{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\nimport numpy as np\nimport os\nimport json\nimport joblib\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LinearRegression, SGDRegressor\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.pipeline import Pipeline\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Create results directory\nPROJECT_DIR = '/Users/adityavikrammahendru/Documents/GitHub/MLProjectHousePricePrediction'\nRESULTS_DIR = os.path.join(PROJECT_DIR, 'results')\nos.makedirs(RESULTS_DIR, exist_ok=True)\n\nprint(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07801b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/adityavikrammahendru/.cache/kagglehub/datasets/arunjangir245/boston-housing-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"arunjangir245/boston-housing-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning: 0\n",
      "Training set: 354 samples\n",
      "Test set: 152 samples\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Save split data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresults/X_train.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m X_test.to_csv(\u001b[33m'\u001b[39m\u001b[33mresults/X_test.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     23\u001b[39m y_train.to_csv(\u001b[33m'\u001b[39m\u001b[33mresults/y_train.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/pandas/core/generic.py:3988\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3977\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3979\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3980\u001b[39m     frame=df,\n\u001b[32m   3981\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3985\u001b[39m     decimal=decimal,\n\u001b[32m   3986\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3988\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4005\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1025\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m   1004\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1006\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m   1007\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m   1008\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1024\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1028\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;66;03m# error: Argument \"quoting\" to \"writer\" has incompatible type \"int\";\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;66;03m# expected \"Literal[0, 1, 2, 3]\"\u001b[39;00m\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    263\u001b[39m         handles.handle,\n\u001b[32m    264\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    269\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    270\u001b[39m     )\n\u001b[32m    272\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/pandas/io/common.py:793\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    791\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    796\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    797\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/pandas/io/common.py:652\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    650\u001b[39m parent = Path(path).parent\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: 'results'"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(os.path.join(PROJECT_DIR, '.cache/kagglehub/datasets/arunjukir245/boston-housing-dataset/versions/2/BostonHousing.csv'))\n",
    "\n",
    "# Handle missing values - fill all numeric columns with median\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "# Verify no missing values\n",
    "print(f\"Missing values after cleaning: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('medv', axis=1)\n",
    "y = df['medv']\n",
    "\n",
    "# Train/test split (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Save split data\n",
    "X_train.to_csv(RESULTS_DIR + '/X_train.csv', index=False)\n",
    "X_test.to_csv(RESULTS_DIR + '/X_test.csv', index=False)\n",
    "y_train.to_csv(RESULTS_DIR + '/y_train.csv', index=False)\n",
    "y_test.to_csv(RESULTS_DIR + '/y_test.csv', index=False)\n",
    "print(\"Data saved to models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Evaluate model and return metrics\"\"\"\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'train_mse': mean_squared_error(y_train, y_train_pred),\n",
    "        'test_mse': mean_squared_error(y_test, y_test_pred),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
    "        'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
    "        'train_r2': r2_score(y_train, y_train_pred),\n",
    "        'test_r2': r2_score(y_test, y_test_pred),\n",
    "    }\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    metrics['cv_r2_mean'] = cv_scores.mean()\n",
    "    metrics['cv_r2_std'] = cv_scores.std()\n",
    "    \n",
    "    return metrics, y_test_pred\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"Print model metrics\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Model: {metrics['model_name']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Train MSE: {metrics['train_mse']:.4f} | Test MSE: {metrics['test_mse']:.4f}\")\n",
    "    print(f\"Train RMSE: {metrics['train_rmse']:.4f} | Test RMSE: {metrics['test_rmse']:.4f}\")\n",
    "    print(f\"Train MAE: {metrics['train_mae']:.4f} | Test MAE: {metrics['test_mae']:.4f}\")\n",
    "    print(f\"Train R\u00b2: {metrics['train_r2']:.4f} | Test R\u00b2: {metrics['test_r2']:.4f}\")\n",
    "    print(f\"CV R\u00b2 (mean\u00b1std): {metrics['cv_r2_mean']:.4f} \u00b1 {metrics['cv_r2_std']:.4f}\")\n",
    "\n",
    "    # Overfitting/Underfitting analysis\n",
    "    diff = metrics['train_r2'] - metrics['test_r2']\n",
    "    if diff > 0.1:\n",
    "        print(f\"\u26a0\ufe0f  Overfitting detected (train-test R\u00b2 gap: {diff:.4f})\")\n",
    "    elif metrics['train_r2'] < 0.5 and metrics['test_r2'] < 0.5:\n",
    "        print(f\"\u26a0\ufe0f  Underfitting detected (low R\u00b2 on both sets)\")\n",
    "    else:\n",
    "        print(f\"\u2705 Good fit\")\n",
    "\n",
    "print(\"Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear_univariate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. UNIVARIATE LINEAR REGRESSION (rm \u2192 medv)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "Model: Linear Regression (Univariate)\n",
      "==================================================\n",
      "Train MSE: 44.9427 | Test MSE: 40.3866\n",
      "Train RMSE: 6.7039 | Test RMSE: 6.3550\n",
      "Train MAE: 4.5033 | Test MAE: 4.3207\n",
      "Train R\u00b2: 0.4887 | Test R\u00b2: 0.4580\n",
      "CV R\u00b2 (mean\u00b1std): 0.4524 \u00b1 0.1773\n",
      "\u26a0\ufe0f  Underfitting detected (low R\u00b2 on both sets)\n",
      "\n",
      "\u2705 Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 1. UNIVARIATE LINEAR REGRESSION\n",
    "# Using only 'rm' (rooms) - strongest correlation with target\n",
    "print(\"=\"*60)\n",
    "print(\"1. UNIVARIATE LINEAR REGRESSION (rm \u2192 medv)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train_uni = X_train[['rm']]\n",
    "X_test_uni = X_test[['rm']]\n",
    "\n",
    "lr_uni = LinearRegression()\n",
    "lr_uni.fit(X_train_uni, y_train)\n",
    "\n",
    "metrics_uni, pred_uni = evaluate_model(lr_uni, X_train_uni, X_test_uni, y_train, y_test, \"Linear Regression (Univariate)\")\n",
    "print_metrics(metrics_uni)\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_uni, RESULTS_DIR + '/linear_univariate.joblib')\n",
    "np.save(RESULTS_DIR + '/pred_linear_univariate.npy', pred_uni)\n",
    "\n",
    "# Save metrics\n",
    "with open(RESULTS_DIR + '/metrics_linear_univariate.json', 'w') as f:\n",
    "    json.dump(metrics_uni, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear_multivariate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "2. MULTIVARIATE LINEAR REGRESSION (all features)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "Model: Linear Regression (Multivariate)\n",
      "==================================================\n",
      "Train MSE: 22.5704 | Test MSE: 21.6188\n",
      "Train RMSE: 4.7508 | Test RMSE: 4.6496\n",
      "Train MAE: 3.3590 | Test MAE: 3.1761\n",
      "Train R\u00b2: 0.7432 | Test R\u00b2: 0.7099\n",
      "CV R\u00b2 (mean\u00b1std): 0.6880 \u00b1 0.0923\n",
      "\u2705 Good fit\n",
      "\n",
      "Top 5 Most Important Features:\n",
      "    feature  coefficient\n",
      "4       nox   -15.423388\n",
      "5        rm     4.056626\n",
      "3      chas     3.121412\n",
      "7       dis    -1.379212\n",
      "10  ptratio    -0.912924\n",
      "\n",
      "\u2705 Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 2. MULTIVARIATE LINEAR REGRESSION\n",
    "# Using all features\n",
    "print(\"=\"*60)\n",
    "print(\"2. MULTIVARIATE LINEAR REGRESSION (all features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lr_multi = LinearRegression()\n",
    "lr_multi.fit(X_train, y_train)\n",
    "\n",
    "metrics_multi, pred_multi = evaluate_model(lr_multi, X_train, X_test, y_train, y_test, \"Linear Regression (Multivariate)\")\n",
    "print_metrics(metrics_multi)\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': lr_multi.coef_\n",
    "}).sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(feature_importance.head())\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_multi, RESULTS_DIR + '/linear_multivariate.joblib')\n",
    "np.save(RESULTS_DIR + '/pred_linear_multivariate.npy', pred_multi)\n",
    "\n",
    "# Save metrics\n",
    "with open(RESULTS_DIR + '/metrics_linear_multivariate.json', 'w') as f:\n",
    "    json.dump(metrics_multi, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "3. FEATURE SELECTION - Top Correlated Features\n",
      "============================================================\n",
      "Selected features: ['lstat', 'rm', 'ptratio', 'indus', 'tax', 'nox']\n",
      "\n",
      "==================================================\n",
      "Model: Linear Regression (Feature Selection)\n",
      "==================================================\n",
      "Train MSE: 27.4869 | Test MSE: 26.0001\n",
      "Train RMSE: 5.2428 | Test RMSE: 5.0990\n",
      "Train MAE: 3.6675 | Test MAE: 3.5702\n",
      "Train R\u00b2: 0.6873 | Test R\u00b2: 0.6511\n",
      "CV R\u00b2 (mean\u00b1std): 0.6512 \u00b1 0.0902\n",
      "\u2705 Good fit\n",
      "\n",
      "\u2705 Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 3. FEATURE SELECTION - Using top correlated features\n",
    "print(\"=\"*60)\n",
    "print(\"3. FEATURE SELECTION - Top Correlated Features\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Select top features based on correlation with target\n",
    "correlations = df.corr()['medv'].drop('medv').abs().sort_values(ascending=False)\n",
    "top_features = correlations.head(6).index.tolist()\n",
    "print(f\"Selected features: {top_features}\")\n",
    "\n",
    "X_train_fs = X_train[top_features]\n",
    "X_test_fs = X_test[top_features]\n",
    "\n",
    "lr_fs = LinearRegression()\n",
    "lr_fs.fit(X_train_fs, y_train)\n",
    "\n",
    "metrics_fs, pred_fs = evaluate_model(lr_fs, X_train_fs, X_test_fs, y_train, y_test, \"Linear Regression (Feature Selection)\")\n",
    "print_metrics(metrics_fs)\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_fs, RESULTS_DIR + '/linear_feature_selection.joblib')\n",
    "np.save(RESULTS_DIR + '/pred_linear_feature_selection.npy', pred_fs)\n",
    "\n",
    "with open(RESULTS_DIR + '/metrics_linear_feature_selection.json', 'w') as f:\n",
    "    json.dump(metrics_fs, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polynomial_regression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "4. POLYNOMIAL REGRESSION\n",
      "============================================================\n",
      "\n",
      "--- Degree 2 ---\n",
      "\n",
      "==================================================\n",
      "Model: Polynomial Regression (degree=2)\n",
      "==================================================\n",
      "Train MSE: 40.7690 | Test MSE: 32.2518\n",
      "Train RMSE: 6.3851 | Test RMSE: 5.6791\n",
      "Train MAE: 4.2943 | Test MAE: 4.0268\n",
      "Train R\u00b2: 0.5362 | Test R\u00b2: 0.5672\n",
      "CV R\u00b2 (mean\u00b1std): 0.4829 \u00b1 0.2243\n",
      "\u2705 Good fit\n",
      "\n",
      "--- Degree 3 ---\n",
      "\n",
      "==================================================\n",
      "Model: Polynomial Regression (degree=3)\n",
      "==================================================\n",
      "Train MSE: 39.6337 | Test MSE: 31.1067\n",
      "Train RMSE: 6.2955 | Test RMSE: 5.5773\n",
      "Train MAE: 4.2922 | Test MAE: 3.9042\n",
      "Train R\u00b2: 0.5491 | Test R\u00b2: 0.5825\n",
      "CV R\u00b2 (mean\u00b1std): 0.4908 \u00b1 0.2045\n",
      "\u2705 Good fit\n",
      "\n",
      "============================================================\n",
      "POLYNOMIAL DEGREE COMPARISON\n",
      "============================================================\n",
      "Degree 2: Train R\u00b2=0.5362, Test R\u00b2=0.5672, CV R\u00b2=0.4829\n",
      "Degree 3: Train R\u00b2=0.5491, Test R\u00b2=0.5825, CV R\u00b2=0.4908\n",
      "\n",
      "\u2705 Polynomial models saved!\n"
     ]
    }
   ],
   "source": [
    "# 4. POLYNOMIAL REGRESSION\n",
    "print(\"=\"*60)\n",
    "print(\"4. POLYNOMIAL REGRESSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_poly = {}\n",
    "\n",
    "for degree in [2, 3]:\n",
    "    print(f\"\\n--- Degree {degree} ---\")\n",
    "    \n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train_uni)\n",
    "    X_test_poly = poly.transform(X_test_uni)\n",
    "    \n",
    "    lr_poly = LinearRegression()\n",
    "    lr_poly.fit(X_train_poly, y_train)\n",
    "    \n",
    "    metrics_poly, pred_poly = evaluate_model(\n",
    "        lr_poly, X_train_poly, X_test_poly, y_train, y_test, \n",
    "        f\"Polynomial Regression (degree={degree})\"\n",
    "    )\n",
    "    print_metrics(metrics_poly)\n",
    "    \n",
    "    results_poly[degree] = {\n",
    "        'model': lr_poly,\n",
    "        'metrics': metrics_poly,\n",
    "        'predictions': pred_poly,\n",
    "        'poly': poly\n",
    "    }\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(lr_poly, fRESULTS_DIR + '/polynomial_degree{degree}.joblib')\n",
    "    joblib.dump(poly, fRESULTS_DIR + '/polynomial_transformer_degree{degree}.joblib')\n",
    "    np.save(fRESULTS_DIR + '/pred_polynomial_degree{degree}.npy', pred_poly)\n",
    "    \n",
    "    with open(f'metrics_polynomial_degree{degree}.json', 'w') as f:\n",
    "        json.dump(metrics_poly, f, indent=2)\n",
    "\n",
    "# Compare degrees\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POLYNOMIAL DEGREE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "for degree, data in results_poly.items():\n",
    "    m = data['metrics']\n",
    "    print(f\"Degree {degree}: Train R\u00b2={m['train_r2']:.4f}, Test R\u00b2={m['test_r2']:.4f}, CV R\u00b2={m['cv_r2_mean']:.4f}\")\n",
    "\n",
    "print(\"\\n\u2705 Polynomial models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradient_descent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "5. GRADIENT DESCENT OPTIMIZATION (SGDRegressor)\n",
      "============================================================\n",
      "\n",
      "--- SGD (constant) ---\n",
      "\n",
      "==================================================\n",
      "Model: SGD (constant)\n",
      "==================================================\n",
      "Train MSE: 23.3203 | Test MSE: 22.7980\n",
      "Train RMSE: 4.8291 | Test RMSE: 4.7747\n",
      "Train MAE: 3.4790 | Test MAE: 3.2964\n",
      "Train R\u00b2: 0.7347 | Test R\u00b2: 0.6940\n",
      "CV R\u00b2 (mean\u00b1std): 0.6657 \u00b1 0.0882\n",
      "\u2705 Good fit\n",
      "\n",
      "--- SGD (adaptive) ---\n",
      "\n",
      "==================================================\n",
      "Model: SGD (adaptive)\n",
      "==================================================\n",
      "Train MSE: 22.6660 | Test MSE: 21.5913\n",
      "Train RMSE: 4.7609 | Test RMSE: 4.6466\n",
      "Train MAE: 3.3544 | Test MAE: 3.1626\n",
      "Train R\u00b2: 0.7421 | Test R\u00b2: 0.7102\n",
      "CV R\u00b2 (mean\u00b1std): 0.6901 \u00b1 0.0900\n",
      "\u2705 Good fit\n",
      "\n",
      "\u2705 Gradient descent models saved!\n"
     ]
    }
   ],
   "source": [
    "# 5. GRADIENT DESCENT (SGDRegressor)\n",
    "print(\"=\"*60)\n",
    "print(\"5. GRADIENT DESCENT OPTIMIZATION (SGDRegressor)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Scale features for gradient descent\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SGDRegressor with different configurations\n",
    "sgd_configs = [\n",
    "    {'loss': 'squared_error', 'learning_rate': 'constant', 'eta0': 0.01, 'name': 'SGD (constant)'},\n",
    "    {'loss': 'squared_error', 'learning_rate': 'adaptive', 'eta0': 0.01, 'name': 'SGD (adaptive)'},\n",
    "]\n",
    "\n",
    "results_sgd = {}\n",
    "\n",
    "for config in sgd_configs:\n",
    "    print(f\"\\n--- {config['name']} ---\")\n",
    "    \n",
    "    sgd = SGDRegressor(\n",
    "        loss=config['loss'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        eta0=config['eta0'],\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "    \n",
    "    sgd.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    metrics_sgd, pred_sgd = evaluate_model(\n",
    "        sgd, X_train_scaled, X_test_scaled, y_train, y_test,\n",
    "        config['name']\n",
    "    )\n",
    "    print_metrics(metrics_sgd)\n",
    "    \n",
    "    results_sgd[config['name']] = {\n",
    "        'model': sgd,\n",
    "        'metrics': metrics_sgd,\n",
    "        'predictions': pred_sgd\n",
    "    }\n",
    "    \n",
    "    # Save model and scaler\n",
    "    safe_name = config['name'].replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    joblib.dump(sgd, fRESULTS_DIR + '/{safe_name}.joblib')\n",
    "    np.save(fRESULTS_DIR + '/pred_{safe_name}.npy', pred_sgd)\n",
    "    \n",
    "    with open(f'metrics_{safe_name}.json', 'w') as f:\n",
    "        json.dump(metrics_sgd, f, indent=2)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, RESULTS_DIR + '/scaler.joblib')\n",
    "\n",
    "print(\"\\n\u2705 Gradient descent models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross_validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "6. CROSS-VALIDATION ANALYSIS (5-Fold)\n",
      "============================================================\n",
      "\n",
      "Linear (Uni):\n",
      "  R\u00b2: 0.4524 \u00b1 0.1773\n",
      "  MSE: 46.0120 \u00b1 11.4529\n",
      "\n",
      "Linear (Multi):\n",
      "  R\u00b2: 0.6880 \u00b1 0.0923\n",
      "  MSE: 25.9884 \u00b1 4.7246\n",
      "\n",
      "Linear (FS):\n",
      "  R\u00b2: 0.6512 \u00b1 0.0902\n",
      "  MSE: 29.4805 \u00b1 6.5223\n",
      "\n",
      "\u2705 Cross-validation results saved!\n"
     ]
    }
   ],
   "source": [
    "# 6. CROSS-VALIDATION ANALYSIS\n",
    "print(\"=\"*60)\n",
    "print(\"6. CROSS-VALIDATION ANALYSIS (5-Fold)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models_to_cv = {\n",
    "    'Linear (Uni)': (lr_uni, X_train_uni),\n",
    "    'Linear (Multi)': (lr_multi, X_train),\n",
    "    'Linear (FS)': (lr_fs, X_train_fs),\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for name, (model, X_data) in models_to_cv.items():\n",
    "    # R\u00b2 cross-validation\n",
    "    cv_r2 = cross_val_score(model, X_data, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    # Negative MSE cross-validation\n",
    "    cv_mse = cross_val_score(model, X_data, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'r2_mean': cv_r2.mean(),\n",
    "        'r2_std': cv_r2.std(),\n",
    "        'mse_mean': -cv_mse.mean(),\n",
    "        'mse_std': cv_mse.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  R\u00b2: {cv_r2.mean():.4f} \u00b1 {cv_r2.std():.4f}\")\n",
    "    print(f\"  MSE: {-cv_mse.mean():.4f} \u00b1 {cv_mse.std():.4f}\")\n",
    "\n",
    "# Save CV results\n",
    "with open(RESULTS_DIR + '/cv_results.json', 'w') as f:\n",
    "    json.dump(cv_results, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Cross-validation results saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "7. FINAL MODEL COMPARISON\n",
      "============================================================\n",
      "\n",
      "Model Performance Ranking (by Test R\u00b2):\n",
      "                           model_name  train_r2  test_r2  train_rmse  test_rmse  cv_r2_mean  cv_r2_std\n",
      "     Linear Regression (Multivariate)  0.743216 0.709866    4.750834   4.649599    0.688038   0.092316\n",
      "Linear Regression (Feature Selection)  0.687281 0.651066    5.242799   5.099033    0.651222   0.090185\n",
      "     Polynomial Regression (degree=3)  0.549087 0.582533    6.295528   5.577342    0.490782   0.204544\n",
      "     Polynomial Regression (degree=2)  0.536170 0.567166    6.385063   5.679065    0.482943   0.224297\n",
      "       Linear Regression (Univariate)  0.488686 0.457993    6.703935   6.355044    0.452441   0.177267\n",
      "\n",
      "\ud83c\udfc6 Best Model: Linear Regression (Multivariate)\n",
      "   Test R\u00b2: 0.7099\n",
      "\n",
      "\u2705 Comparison saved!\n"
     ]
    }
   ],
   "source": [
    "# 7. FINAL MODEL COMPARISON\n",
    "print(\"=\"*60)\n",
    "print(\"7. FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_metrics = [\n",
    "    metrics_uni,\n",
    "    metrics_multi,\n",
    "    metrics_fs,\n",
    "    results_poly[2]['metrics'],\n",
    "    results_poly[3]['metrics'],\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(all_metrics)\n",
    "comparison_df = comparison_df[['model_name', 'train_r2', 'test_r2', 'train_rmse', 'test_rmse', 'cv_r2_mean', 'cv_r2_std']]\n",
    "comparison_df = comparison_df.sort_values('test_r2', ascending=False)\n",
    "\n",
    "print(\"\\nModel Performance Ranking (by Test R\u00b2):\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv(RESULTS_DIR + '/model_comparison.csv', index=False)\n",
    "\n",
    "best_model = comparison_df.iloc[0]['model_name']\n",
    "best_r2 = comparison_df.iloc[0]['test_r2']\n",
    "\n",
    "print(f\"\\n\ud83c\udfc6 Best Model: {best_model}\")\n",
    "print(f\"   Test R\u00b2: {best_r2:.4f}\")\n",
    "\n",
    "print(\"\\n\u2705 Comparison saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROJECT SUMMARY\n",
      "============================================================\n",
      "\n",
      "ALGORITHMS IMPLEMENTED:\n",
      "1. \u2705 Linear Regression (Univariate) - using rm feature\n",
      "2. \u2705 Linear Regression (Multivariate) - using all features\n",
      "3. \u2705 Linear Regression (Feature Selection) - top correlated features\n",
      "4. \u2705 Polynomial Regression (Degree 2 & 3)\n",
      "5. \u2705 Gradient Descent (SGDRegressor)\n",
      "\n",
      "KEY CONCEPTS COVERED:\n",
      "1. \u2705 Regression - predicting house prices\n",
      "2. \u2705 Overfitting vs Underfitting - analyzed in model evaluation\n",
      "3. \u2705 Cross-validation - 5-fold CV performed\n",
      "4. \u2705 Feature Selection - using correlation analysis\n",
      "\n",
      "FILES SAVED IN 'models/':\n",
      "- Models: *.joblib\n",
      "- Predictions: *.npy\n",
      "- Metrics: *.json\n",
      "- Data splits: X_train.csv, X_test.csv, y_train.csv, y_test.csv\n",
      "- Model comparison: model_comparison.csv\n",
      "\n",
      "Total files saved: 26\n",
      "\n",
      "Files: ['SGD_adaptive.joblib', 'SGD_constant.joblib', 'X_test.csv', 'X_train.csv', 'cv_results.json', 'linear_feature_selection.joblib', 'linear_multivariate.joblib', 'linear_univariate.joblib', 'metrics_linear_feature_selection.json', 'metrics_linear_multivariate.json', 'metrics_linear_univariate.json', 'model_comparison.csv', 'polynomial_degree2.joblib', 'polynomial_degree3.joblib', 'polynomial_transformer_degree2.joblib', 'polynomial_transformer_degree3.joblib', 'pred_SGD_adaptive.npy', 'pred_SGD_constant.npy', 'pred_linear_feature_selection.npy', 'pred_linear_multivariate.npy', 'pred_linear_univariate.npy', 'pred_polynomial_degree2.npy', 'pred_polynomial_degree3.npy', 'scaler.joblib', 'y_test.csv', 'y_train.csv']\n"
     ]
    }
   ],
   "source": [
    "# 8. SUMMARY\n",
    "print(\"=\"*60)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "ALGORITHMS IMPLEMENTED:\n",
    "1. \u2705 Linear Regression (Univariate) - using rm feature\n",
    "2. \u2705 Linear Regression (Multivariate) - using all features\n",
    "3. \u2705 Linear Regression (Feature Selection) - top correlated features\n",
    "4. \u2705 Polynomial Regression (Degree 2 & 3)\n",
    "5. \u2705 Gradient Descent (SGDRegressor)\n",
    "\n",
    "KEY CONCEPTS COVERED:\n",
    "1. \u2705 Regression - predicting house prices\n",
    "2. \u2705 Overfitting vs Underfitting - analyzed in model evaluation\n",
    "3. \u2705 Cross-validation - 5-fold CV performed\n",
    "4. \u2705 Feature Selection - using correlation analysis\n",
    "\n",
    "FILES SAVED IN RESULTS_DIR + '/':\n",
    "- Models: *.joblib\n",
    "- Predictions: *.npy\n",
    "- Metrics: *.json\n",
    "- Data splits: X_train.csv, X_test.csv, y_train.csv, y_test.csv\n",
    "- Model comparison: model_comparison.csv\n",
    "\"\"\")\n",
    "\n",
    "# List all saved files\n",
    "saved_files = os.listdir('models')\n",
    "print(f\"Total files saved: {len(saved_files)}\")\n",
    "print(\"\\nFiles:\", sorted(saved_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project",
   "language": "python",
   "name": "ml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}