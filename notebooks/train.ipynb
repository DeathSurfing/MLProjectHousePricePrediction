{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create results directory\n",
    "PROJECT_DIR = '../'\n",
    "RESULTS_DIR = os.path.join(PROJECT_DIR, 'results')\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07801b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/adityavikrammahendru/.cache/kagglehub/datasets/arunjangir245/boston-housing-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"arunjangir245/boston-housing-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning: 0\n",
      "Training set: 354 samples\n",
      "Test set: 152 samples\n",
      "Data saved to results/\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset using the path from kagglehub\n",
    "df = pd.read_csv(path + '/BostonHousing.csv')\n",
    "\n",
    "# Handle missing values - fill all numeric columns with median\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "# Verify no missing values\n",
    "print(f\"Missing values after cleaning: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('medv', axis=1)\n",
    "y = df['medv']\n",
    "\n",
    "# Train/test split (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Save split data\n",
    "X_train.to_csv(RESULTS_DIR + '/X_train.csv', index=False)\n",
    "X_test.to_csv(RESULTS_DIR + '/X_test.csv', index=False)\n",
    "y_train.to_csv(RESULTS_DIR + '/y_train.csv', index=False)\n",
    "y_test.to_csv(RESULTS_DIR + '/y_test.csv', index=False)\n",
    "print(\"Data saved to results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "evaluation_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Evaluate model and return metrics\"\"\"\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'train_mse': mean_squared_error(y_train, y_train_pred),\n",
    "        'test_mse': mean_squared_error(y_test, y_test_pred),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
    "        'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
    "        'train_r2': r2_score(y_train, y_train_pred),\n",
    "        'test_r2': r2_score(y_test, y_test_pred),\n",
    "    }\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    metrics['cv_r2_mean'] = cv_scores.mean()\n",
    "    metrics['cv_r2_std'] = cv_scores.std()\n",
    "    \n",
    "    return metrics, y_test_pred\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"Print model metrics\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Model: {metrics['model_name']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Train MSE: {metrics['train_mse']:.4f} | Test MSE: {metrics['test_mse']:.4f}\")\n",
    "    print(f\"Train RMSE: {metrics['train_rmse']:.4f} | Test RMSE: {metrics['test_rmse']:.4f}\")\n",
    "    print(f\"Train MAE: {metrics['train_mae']:.4f} | Test MAE: {metrics['test_mae']:.4f}\")\n",
    "    print(f\"Train RÂ²: {metrics['train_r2']:.4f} | Test RÂ²: {metrics['test_r2']:.4f}\")\n",
    "    print(f\"CV RÂ² (meanÂ±std): {metrics['cv_r2_mean']:.4f} Â± {metrics['cv_r2_std']:.4f}\")\n",
    "\n",
    "    # Overfitting/Underfitting analysis\n",
    "    diff = metrics['train_r2'] - metrics['test_r2']\n",
    "    if diff > 0.1:\n",
    "        print(f\"âš ï¸  Overfitting detected (train-test RÂ² gap: {diff:.4f})\")\n",
    "    elif metrics['train_r2'] < 0.5 and metrics['test_r2'] < 0.5:\n",
    "        print(f\"âš ï¸  Underfitting detected (low RÂ² on both sets)\")\n",
    "    else:\n",
    "        print(f\"âœ… Good fit\")\n",
    "\n",
    "print(\"Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "linear_univariate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. UNIVARIATE LINEAR REGRESSION (rm â†’ medv)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "Model: Linear Regression (Univariate)\n",
      "==================================================\n",
      "Train MSE: 44.9427 | Test MSE: 40.3866\n",
      "Train RMSE: 6.7039 | Test RMSE: 6.3550\n",
      "Train MAE: 4.5033 | Test MAE: 4.3207\n",
      "Train RÂ²: 0.4887 | Test RÂ²: 0.4580\n",
      "CV RÂ² (meanÂ±std): 0.4524 Â± 0.1773\n",
      "âš ï¸  Underfitting detected (low RÂ² on both sets)\n",
      "\n",
      "âœ… Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 1. UNIVARIATE LINEAR REGRESSION\n",
    "# Using only 'rm' (rooms) - strongest correlation with target\n",
    "print(\"=\"*60)\n",
    "print(\"1. UNIVARIATE LINEAR REGRESSION (rm â†’ medv)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train_uni = X_train[['rm']]\n",
    "X_test_uni = X_test[['rm']]\n",
    "\n",
    "lr_uni = LinearRegression()\n",
    "lr_uni.fit(X_train_uni, y_train)\n",
    "\n",
    "metrics_uni, pred_uni = evaluate_model(lr_uni, X_train_uni, X_test_uni, y_train, y_test, \"Linear Regression (Univariate)\")\n",
    "print_metrics(metrics_uni)\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_uni, RESULTS_DIR + '/linear_univariate.joblib')\n",
    "np.save(RESULTS_DIR + '/pred_linear_univariate.npy', pred_uni)\n",
    "\n",
    "# Save metrics\n",
    "with open(RESULTS_DIR + '/metrics_linear_univariate.json', 'w') as f:\n",
    "    json.dump(metrics_uni, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ… Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "linear_multivariate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "2. MULTIVARIATE LINEAR REGRESSION (all features)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "Model: Linear Regression (Multivariate)\n",
      "==================================================\n",
      "Train MSE: 22.5704 | Test MSE: 21.6188\n",
      "Train RMSE: 4.7508 | Test RMSE: 4.6496\n",
      "Train MAE: 3.3590 | Test MAE: 3.1761\n",
      "Train RÂ²: 0.7432 | Test RÂ²: 0.7099\n",
      "CV RÂ² (meanÂ±std): 0.6880 Â± 0.0923\n",
      "âœ… Good fit\n",
      "\n",
      "Top 5 Most Important Features:\n",
      "    feature  coefficient\n",
      "4       nox   -15.423388\n",
      "5        rm     4.056626\n",
      "3      chas     3.121412\n",
      "7       dis    -1.379212\n",
      "10  ptratio    -0.912924\n",
      "\n",
      "âœ… Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 2. MULTIVARIATE LINEAR REGRESSION\n",
    "# Using all features\n",
    "print(\"=\"*60)\n",
    "print(\"2. MULTIVARIATE LINEAR REGRESSION (all features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lr_multi = LinearRegression()\n",
    "lr_multi.fit(X_train, y_train)\n",
    "\n",
    "metrics_multi, pred_multi = evaluate_model(lr_multi, X_train, X_test, y_train, y_test, \"Linear Regression (Multivariate)\")\n",
    "print_metrics(metrics_multi)\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': lr_multi.coef_\n",
    "}).sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(feature_importance.head())\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_multi, RESULTS_DIR + '/linear_multivariate.joblib')\n",
    "np.save(RESULTS_DIR + '/pred_linear_multivariate.npy', pred_multi)\n",
    "\n",
    "# Save metrics\n",
    "with open(RESULTS_DIR + '/metrics_linear_multivariate.json', 'w') as f:\n",
    "    json.dump(metrics_multi, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ… Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "feature_selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "3. FEATURE SELECTION - Top Correlated Features\n",
      "============================================================\n",
      "Selected features: ['lstat', 'rm', 'ptratio', 'indus', 'tax', 'nox']\n",
      "\n",
      "==================================================\n",
      "Model: Linear Regression (Feature Selection)\n",
      "==================================================\n",
      "Train MSE: 27.4869 | Test MSE: 26.0001\n",
      "Train RMSE: 5.2428 | Test RMSE: 5.0990\n",
      "Train MAE: 3.6675 | Test MAE: 3.5702\n",
      "Train RÂ²: 0.6873 | Test RÂ²: 0.6511\n",
      "CV RÂ² (meanÂ±std): 0.6512 Â± 0.0902\n",
      "âœ… Good fit\n",
      "\n",
      "âœ… Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 3. FEATURE SELECTION - Using top correlated features\n",
    "print(\"=\"*60)\n",
    "print(\"3. FEATURE SELECTION - Top Correlated Features\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Select top features based on correlation with target\n",
    "correlations = df.corr()['medv'].drop('medv').abs().sort_values(ascending=False)\n",
    "top_features = correlations.head(6).index.tolist()\n",
    "print(f\"Selected features: {top_features}\")\n",
    "\n",
    "X_train_fs = X_train[top_features]\n",
    "X_test_fs = X_test[top_features]\n",
    "\n",
    "lr_fs = LinearRegression()\n",
    "lr_fs.fit(X_train_fs, y_train)\n",
    "\n",
    "metrics_fs, pred_fs = evaluate_model(lr_fs, X_train_fs, X_test_fs, y_train, y_test, \"Linear Regression (Feature Selection)\")\n",
    "print_metrics(metrics_fs)\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_fs, RESULTS_DIR + '/linear_feature_selection.joblib')\n",
    "np.save(RESULTS_DIR + '/pred_linear_feature_selection.npy', pred_fs)\n",
    "\n",
    "with open(RESULTS_DIR + '/metrics_linear_feature_selection.json', 'w') as f:\n",
    "    json.dump(metrics_fs, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ… Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "polynomial_regression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "4. POLYNOMIAL REGRESSION\n",
      "============================================================\n",
      "\n",
      "--- Degree 2 ---\n",
      "\n",
      "==================================================\n",
      "Model: Polynomial Regression (degree=2)\n",
      "==================================================\n",
      "Train MSE: 40.7690 | Test MSE: 32.2518\n",
      "Train RMSE: 6.3851 | Test RMSE: 5.6791\n",
      "Train MAE: 4.2943 | Test MAE: 4.0268\n",
      "Train RÂ²: 0.5362 | Test RÂ²: 0.5672\n",
      "CV RÂ² (meanÂ±std): 0.4829 Â± 0.2243\n",
      "âœ… Good fit\n",
      "\n",
      "--- Degree 3 ---\n",
      "\n",
      "==================================================\n",
      "Model: Polynomial Regression (degree=3)\n",
      "==================================================\n",
      "Train MSE: 39.6337 | Test MSE: 31.1067\n",
      "Train RMSE: 6.2955 | Test RMSE: 5.5773\n",
      "Train MAE: 4.2922 | Test MAE: 3.9042\n",
      "Train RÂ²: 0.5491 | Test RÂ²: 0.5825\n",
      "CV RÂ² (meanÂ±std): 0.4908 Â± 0.2045\n",
      "âœ… Good fit\n",
      "\n",
      "============================================================\n",
      "POLYNOMIAL DEGREE COMPARISON\n",
      "============================================================\n",
      "Degree 2: Train RÂ²=0.5362, Test RÂ²=0.5672, CV RÂ²=0.4829\n",
      "Degree 3: Train RÂ²=0.5491, Test RÂ²=0.5825, CV RÂ²=0.4908\n",
      "\n",
      "âœ… Polynomial models saved!\n"
     ]
    }
   ],
   "source": [
    "# 4. POLYNOMIAL REGRESSION\n",
    "print(\"=\"*60)\n",
    "print(\"4. POLYNOMIAL REGRESSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_poly = {}\n",
    "\n",
    "for degree in [2, 3]:\n",
    "    print(f\"\\n--- Degree {degree} ---\")\n",
    "    \n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train_uni)\n",
    "    X_test_poly = poly.transform(X_test_uni)\n",
    "    \n",
    "    lr_poly = LinearRegression()\n",
    "    lr_poly.fit(X_train_poly, y_train)\n",
    "    \n",
    "    metrics_poly, pred_poly = evaluate_model(\n",
    "        lr_poly, X_train_poly, X_test_poly, y_train, y_test, \n",
    "        f\"Polynomial Regression (degree={degree})\"\n",
    "    )\n",
    "    print_metrics(metrics_poly)\n",
    "    \n",
    "    results_poly[degree] = {\n",
    "        'model': lr_poly,\n",
    "        'metrics': metrics_poly,\n",
    "        'predictions': pred_poly,\n",
    "        'poly': poly\n",
    "    }\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(lr_poly, f'{RESULTS_DIR}/polynomial_degree{degree}.joblib')\n",
    "    joblib.dump(poly, f'{RESULTS_DIR}/polynomial_transformer_degree{degree}.joblib')\n",
    "    np.save(f'{RESULTS_DIR}/pred_polynomial_degree{degree}.npy', pred_poly)\n",
    "    \n",
    "    with open(f'{RESULTS_DIR}/metrics_polynomial_degree{degree}.json', 'w') as f:\n",
    "        json.dump(metrics_poly, f, indent=2)\n",
    "\n",
    "# Compare degrees\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POLYNOMIAL DEGREE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "for degree, data in results_poly.items():\n",
    "    m = data['metrics']\n",
    "    print(f\"Degree {degree}: Train RÂ²={m['train_r2']:.4f}, Test RÂ²={m['test_r2']:.4f}, CV RÂ²={m['cv_r2_mean']:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… Polynomial models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "gradient_descent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "5. GRADIENT DESCENT OPTIMIZATION (SGDRegressor)\n",
      "============================================================\n",
      "\n",
      "--- SGD (constant) ---\n",
      "\n",
      "==================================================\n",
      "Model: SGD (constant)\n",
      "==================================================\n",
      "Train MSE: 23.3203 | Test MSE: 22.7980\n",
      "Train RMSE: 4.8291 | Test RMSE: 4.7747\n",
      "Train MAE: 3.4790 | Test MAE: 3.2964\n",
      "Train RÂ²: 0.7347 | Test RÂ²: 0.6940\n",
      "CV RÂ² (meanÂ±std): 0.6657 Â± 0.0882\n",
      "âœ… Good fit\n",
      "\n",
      "--- SGD (adaptive) ---\n",
      "\n",
      "==================================================\n",
      "Model: SGD (adaptive)\n",
      "==================================================\n",
      "Train MSE: 22.6660 | Test MSE: 21.5913\n",
      "Train RMSE: 4.7609 | Test RMSE: 4.6466\n",
      "Train MAE: 3.3544 | Test MAE: 3.1626\n",
      "Train RÂ²: 0.7421 | Test RÂ²: 0.7102\n",
      "CV RÂ² (meanÂ±std): 0.6901 Â± 0.0900\n",
      "âœ… Good fit\n",
      "\n",
      "âœ… Gradient descent models saved!\n"
     ]
    }
   ],
   "source": [
    "# 5. GRADIENT DESCENT (SGDRegressor)\n",
    "print(\"=\"*60)\n",
    "print(\"5. GRADIENT DESCENT OPTIMIZATION (SGDRegressor)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Scale features for gradient descent\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SGDRegressor with different configurations\n",
    "sgd_configs = [\n",
    "    {'loss': 'squared_error', 'learning_rate': 'constant', 'eta0': 0.01, 'name': 'SGD (constant)'},\n",
    "    {'loss': 'squared_error', 'learning_rate': 'adaptive', 'eta0': 0.01, 'name': 'SGD (adaptive)'},\n",
    "]\n",
    "\n",
    "results_sgd = {}\n",
    "\n",
    "for config in sgd_configs:\n",
    "    print(f\"\\n--- {config['name']} ---\")\n",
    "    \n",
    "    sgd = SGDRegressor(\n",
    "        loss=config['loss'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        eta0=config['eta0'],\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "    \n",
    "    sgd.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    metrics_sgd, pred_sgd = evaluate_model(\n",
    "        sgd, X_train_scaled, X_test_scaled, y_train, y_test,\n",
    "        config['name']\n",
    "    )\n",
    "    print_metrics(metrics_sgd)\n",
    "    \n",
    "    results_sgd[config['name']] = {\n",
    "        'model': sgd,\n",
    "        'metrics': metrics_sgd,\n",
    "        'predictions': pred_sgd\n",
    "    }\n",
    "    \n",
    "    # Save model and scaler\n",
    "    safe_name = config['name'].replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    joblib.dump(sgd, f'{RESULTS_DIR}/{safe_name}.joblib')\n",
    "    np.save(f'{RESULTS_DIR}/pred_{safe_name}.npy', pred_sgd)\n",
    "    \n",
    "    with open(f'{RESULTS_DIR}/metrics_{safe_name}.json', 'w') as f:\n",
    "        json.dump(metrics_sgd, f, indent=2)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, f'{RESULTS_DIR}/scaler.joblib')\n",
    "\n",
    "print(\"\\nâœ… Gradient descent models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cross_validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "6. CROSS-VALIDATION ANALYSIS (5-Fold)\n",
      "============================================================\n",
      "\n",
      "Linear (Uni):\n",
      "  RÂ²: 0.4524 Â± 0.1773\n",
      "  MSE: 46.0120 Â± 11.4529\n",
      "\n",
      "Linear (Multi):\n",
      "  RÂ²: 0.6880 Â± 0.0923\n",
      "  MSE: 25.9884 Â± 4.7246\n",
      "\n",
      "Linear (FS):\n",
      "  RÂ²: 0.6512 Â± 0.0902\n",
      "  MSE: 29.4805 Â± 6.5223\n",
      "\n",
      "âœ… Cross-validation results saved!\n"
     ]
    }
   ],
   "source": [
    "# 6. CROSS-VALIDATION ANALYSIS\n",
    "print(\"=\"*60)\n",
    "print(\"6. CROSS-VALIDATION ANALYSIS (5-Fold)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models_to_cv = {\n",
    "    'Linear (Uni)': (lr_uni, X_train_uni),\n",
    "    'Linear (Multi)': (lr_multi, X_train),\n",
    "    'Linear (FS)': (lr_fs, X_train_fs),\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for name, (model, X_data) in models_to_cv.items():\n",
    "    # RÂ² cross-validation\n",
    "    cv_r2 = cross_val_score(model, X_data, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    # Negative MSE cross-validation\n",
    "    cv_mse = cross_val_score(model, X_data, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'r2_mean': cv_r2.mean(),\n",
    "        'r2_std': cv_r2.std(),\n",
    "        'mse_mean': -cv_mse.mean(),\n",
    "        'mse_std': cv_mse.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  RÂ²: {cv_r2.mean():.4f} Â± {cv_r2.std():.4f}\")\n",
    "    print(f\"  MSE: {-cv_mse.mean():.4f} Â± {cv_mse.std():.4f}\")\n",
    "\n",
    "# Save CV results\n",
    "with open(RESULTS_DIR + '/cv_results.json', 'w') as f:\n",
    "    json.dump(cv_results, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ… Cross-validation results saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "model_comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "7. FINAL MODEL COMPARISON\n",
      "============================================================\n",
      "\n",
      "Model Performance Ranking (by Test RÂ²):\n",
      "                           model_name  train_r2  test_r2  train_rmse  test_rmse  cv_r2_mean  cv_r2_std\n",
      "     Linear Regression (Multivariate)  0.743216 0.709866    4.750834   4.649599    0.688038   0.092316\n",
      "Linear Regression (Feature Selection)  0.687281 0.651066    5.242799   5.099033    0.651222   0.090185\n",
      "     Polynomial Regression (degree=3)  0.549087 0.582533    6.295528   5.577342    0.490782   0.204544\n",
      "     Polynomial Regression (degree=2)  0.536170 0.567166    6.385063   5.679065    0.482943   0.224297\n",
      "       Linear Regression (Univariate)  0.488686 0.457993    6.703935   6.355044    0.452441   0.177267\n",
      "\n",
      "ğŸ† Best Model: Linear Regression (Multivariate)\n",
      "   Test RÂ²: 0.7099\n",
      "\n",
      "âœ… Comparison saved!\n"
     ]
    }
   ],
   "source": [
    "# 7. FINAL MODEL COMPARISON\n",
    "print(\"=\"*60)\n",
    "print(\"7. FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_metrics = [\n",
    "    metrics_uni,\n",
    "    metrics_multi,\n",
    "    metrics_fs,\n",
    "    results_poly[2]['metrics'],\n",
    "    results_poly[3]['metrics'],\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(all_metrics)\n",
    "comparison_df = comparison_df[['model_name', 'train_r2', 'test_r2', 'train_rmse', 'test_rmse', 'cv_r2_mean', 'cv_r2_std']]\n",
    "comparison_df = comparison_df.sort_values('test_r2', ascending=False)\n",
    "\n",
    "print(\"\\nModel Performance Ranking (by Test RÂ²):\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv(RESULTS_DIR + '/model_comparison.csv', index=False)\n",
    "\n",
    "best_model = comparison_df.iloc[0]['model_name']\n",
    "best_r2 = comparison_df.iloc[0]['test_r2']\n",
    "\n",
    "print(f\"\\nğŸ† Best Model: {best_model}\")\n",
    "print(f\"   Test RÂ²: {best_r2:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… Comparison saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project",
   "language": "python",
   "name": "ml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
