{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create models directory if not exists\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07801b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/adityavikrammahendru/.cache/kagglehub/datasets/arunjangir245/boston-housing-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"arunjangir245/boston-housing-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 354 samples\n",
      "Test set: 152 samples\n",
      "Data saved to models/\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\ndf = pd.read_csv(path + '/BostonHousing.csv')\n\n# Handle missing values - fill all numeric columns with median\ndf = df.fillna(df.median())\n\n# Verify no missing values\nprint(f\"Missing values after cleaning: {df.isnull().sum().sum()}\")\n\n# Define features and target\nX = df.drop('medv', axis=1)\ny = df['medv']\n\n# Train/test split (70/30)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n\nprint(f\"Training set: {X_train.shape[0]} samples\")\nprint(f\"Test set: {X_test.shape[0]} samples\")\n\n# Save split data\nX_train.to_csv('models/X_train.csv', index=False)\nX_test.to_csv('models/X_test.csv', index=False)\ny_train.to_csv('models/y_train.csv', index=False)\ny_test.to_csv('models/y_test.csv', index=False)\nprint(\"Data saved to models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "evaluation_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Evaluate model and return metrics\"\"\"\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'train_mse': mean_squared_error(y_train, y_train_pred),\n",
    "        'test_mse': mean_squared_error(y_test, y_test_pred),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
    "        'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
    "        'train_r2': r2_score(y_train, y_train_pred),\n",
    "        'test_r2': r2_score(y_test, y_test_pred),\n",
    "    }\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    metrics['cv_r2_mean'] = cv_scores.mean()\n",
    "    metrics['cv_r2_std'] = cv_scores.std()\n",
    "    \n",
    "    return metrics, y_test_pred\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"Print model metrics\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Model: {metrics['model_name']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Train MSE: {metrics['train_mse']:.4f} | Test MSE: {metrics['test_mse']:.4f}\")\n",
    "    print(f\"Train RMSE: {metrics['train_rmse']:.4f} | Test RMSE: {metrics['test_rmse']:.4f}\")\n",
    "    print(f\"Train MAE: {metrics['train_mae']:.4f} | Test MAE: {metrics['test_mae']:.4f}\")\n",
    "    print(f\"Train R\u00b2: {metrics['train_r2']:.4f} | Test R\u00b2: {metrics['test_r2']:.4f}\")\n",
    "    print(f\"CV R\u00b2 (mean\u00b1std): {metrics['cv_r2_mean']:.4f} \u00b1 {metrics['cv_r2_std']:.4f}\")\n",
    "\n",
    "    # Overfitting/Underfitting analysis\n",
    "    diff = metrics['train_r2'] - metrics['test_r2']\n",
    "    if diff > 0.1:\n",
    "        print(f\"\u26a0\ufe0f  Overfitting detected (train-test R\u00b2 gap: {diff:.4f})\")\n",
    "    elif metrics['train_r2'] < 0.5 and metrics['test_r2'] < 0.5:\n",
    "        print(f\"\u26a0\ufe0f  Underfitting detected (low R\u00b2 on both sets)\")\n",
    "    else:\n",
    "        print(f\"\u2705 Good fit\")\n",
    "\n",
    "print(\"Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "linear_univariate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. UNIVARIATE LINEAR REGRESSION (rm \u2192 medv)\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m X_test_uni = X_test[[\u001b[33m'\u001b[39m\u001b[33mrm\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m     10\u001b[39m lr_uni = LinearRegression()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mlr_uni\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_uni\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m metrics_uni, pred_uni = evaluate_model(lr_uni, X_train_uni, X_test_uni, y_train, y_test, \u001b[33m\"\u001b[39m\u001b[33mLinear Regression (Univariate)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m print_metrics(metrics_uni)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/sklearn/base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:630\u001b[39m, in \u001b[36mLinearRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    626\u001b[39m n_jobs_ = \u001b[38;5;28mself\u001b[39m.n_jobs\n\u001b[32m    628\u001b[39m accept_sparse = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.positive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    640\u001b[39m has_sw = sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2919\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2917\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2918\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2920\u001b[39m     out = X, y\n\u001b[32m   2922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1314\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1309\u001b[39m         estimator_name = _check_estimator_name(estimator)\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1311\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1312\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1316\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1317\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1319\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1331\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1333\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1074\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1069\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1070\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1071\u001b[39m     )\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1082\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1083\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:133\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:182\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    168\u001b[39m     msg_err += (\n\u001b[32m    169\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# 1. UNIVARIATE LINEAR REGRESSION\n",
    "# Using only 'rm' (rooms) - strongest correlation with target\n",
    "print(\"=\"*60)\n",
    "print(\"1. UNIVARIATE LINEAR REGRESSION (rm \u2192 medv)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train_uni = X_train[['rm']]\n",
    "X_test_uni = X_test[['rm']]\n",
    "\n",
    "lr_uni = LinearRegression()\n",
    "lr_uni.fit(X_train_uni, y_train)\n",
    "\n",
    "metrics_uni, pred_uni = evaluate_model(lr_uni, X_train_uni, X_test_uni, y_train, y_test, \"Linear Regression (Univariate)\")\n",
    "print_metrics(metrics_uni)\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_uni, 'models/linear_univariate.joblib')\n",
    "np.save('models/pred_linear_univariate.npy', pred_uni)\n",
    "\n",
    "# Save metrics\n",
    "with open('models/metrics_linear_univariate.json', 'w') as f:\n",
    "    json.dump(metrics_uni, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear_multivariate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. MULTIVARIATE LINEAR REGRESSION\n",
    "# Using all features\n",
    "print(\"=\"*60)\n",
    "print(\"2. MULTIVARIATE LINEAR REGRESSION (all features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lr_multi = LinearRegression()\n",
    "lr_multi.fit(X_train, y_train)\n",
    "\n",
    "metrics_multi, pred_multi = evaluate_model(lr_multi, X_train, X_test, y_train, y_test, \"Linear Regression (Multivariate)\")\n",
    "print_metrics(metrics_multi)\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': lr_multi.coef_\n",
    "}).sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(feature_importance.head())\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_multi, 'models/linear_multivariate.joblib')\n",
    "np.save('models/pred_linear_multivariate.npy', pred_multi)\n",
    "\n",
    "# Save metrics\n",
    "with open('models/metrics_linear_multivariate.json', 'w') as f:\n",
    "    json.dump(metrics_multi, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. FEATURE SELECTION - Using top correlated features\n",
    "print(\"=\"*60)\n",
    "print(\"3. FEATURE SELECTION - Top Correlated Features\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Select top features based on correlation with target\n",
    "correlations = df.corr()['medv'].drop('medv').abs().sort_values(ascending=False)\n",
    "top_features = correlations.head(6).index.tolist()\n",
    "print(f\"Selected features: {top_features}\")\n",
    "\n",
    "X_train_fs = X_train[top_features]\n",
    "X_test_fs = X_test[top_features]\n",
    "\n",
    "lr_fs = LinearRegression()\n",
    "lr_fs.fit(X_train_fs, y_train)\n",
    "\n",
    "metrics_fs, pred_fs = evaluate_model(lr_fs, X_train_fs, X_test_fs, y_train, y_test, \"Linear Regression (Feature Selection)\")\n",
    "print_metrics(metrics_fs)\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_fs, 'models/linear_feature_selection.joblib')\n",
    "np.save('models/pred_linear_feature_selection.npy', pred_fs)\n",
    "\n",
    "with open('models/metrics_linear_feature_selection.json', 'w') as f:\n",
    "    json.dump(metrics_fs, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polynomial_regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. POLYNOMIAL REGRESSION\n",
    "print(\"=\"*60)\n",
    "print(\"4. POLYNOMIAL REGRESSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_poly = {}\n",
    "\n",
    "for degree in [2, 3]:\n",
    "    print(f\"\\n--- Degree {degree} ---\")\n",
    "    \n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train_uni)\n",
    "    X_test_poly = poly.transform(X_test_uni)\n",
    "    \n",
    "    lr_poly = LinearRegression()\n",
    "    lr_poly.fit(X_train_poly, y_train)\n",
    "    \n",
    "    metrics_poly, pred_poly = evaluate_model(\n",
    "        lr_poly, X_train_poly, X_test_poly, y_train, y_test, \n",
    "        f\"Polynomial Regression (degree={degree})\"\n",
    "    )\n",
    "    print_metrics(metrics_poly)\n",
    "    \n",
    "    results_poly[degree] = {\n",
    "        'model': lr_poly,\n",
    "        'metrics': metrics_poly,\n",
    "        'predictions': pred_poly,\n",
    "        'poly': poly\n",
    "    }\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(lr_poly, f'models/polynomial_degree{degree}.joblib')\n",
    "    joblib.dump(poly, f'models/polynomial_transformer_degree{degree}.joblib')\n",
    "    np.save(f'models/pred_polynomial_degree{degree}.npy', pred_poly)\n",
    "    \n",
    "    with open(f'metrics_polynomial_degree{degree}.json', 'w') as f:\n",
    "        json.dump(metrics_poly, f, indent=2)\n",
    "\n",
    "# Compare degrees\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POLYNOMIAL DEGREE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "for degree, data in results_poly.items():\n",
    "    m = data['metrics']\n",
    "    print(f\"Degree {degree}: Train R\u00b2={m['train_r2']:.4f}, Test R\u00b2={m['test_r2']:.4f}, CV R\u00b2={m['cv_r2_mean']:.4f}\")\n",
    "\n",
    "print(\"\\n\u2705 Polynomial models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradient_descent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. GRADIENT DESCENT (SGDRegressor)\n",
    "print(\"=\"*60)\n",
    "print(\"5. GRADIENT DESCENT OPTIMIZATION (SGDRegressor)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Scale features for gradient descent\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SGDRegressor with different configurations\n",
    "sgd_configs = [\n",
    "    {'loss': 'squared_error', 'learning_rate': 'constant', 'eta0': 0.01, 'name': 'SGD (constant)'},\n",
    "    {'loss': 'squared_error', 'learning_rate': 'adaptive', 'eta0': 0.01, 'name': 'SGD (adaptive)'},\n",
    "]\n",
    "\n",
    "results_sgd = {}\n",
    "\n",
    "for config in sgd_configs:\n",
    "    print(f\"\\n--- {config['name']} ---\")\n",
    "    \n",
    "    sgd = SGDRegressor(\n",
    "        loss=config['loss'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        eta0=config['eta0'],\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "    \n",
    "    sgd.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    metrics_sgd, pred_sgd = evaluate_model(\n",
    "        sgd, X_train_scaled, X_test_scaled, y_train, y_test,\n",
    "        config['name']\n",
    "    )\n",
    "    print_metrics(metrics_sgd)\n",
    "    \n",
    "    results_sgd[config['name']] = {\n",
    "        'model': sgd,\n",
    "        'metrics': metrics_sgd,\n",
    "        'predictions': pred_sgd\n",
    "    }\n",
    "    \n",
    "    # Save model and scaler\n",
    "    safe_name = config['name'].replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    joblib.dump(sgd, f'models/{safe_name}.joblib')\n",
    "    np.save(f'models/pred_{safe_name}.npy', pred_sgd)\n",
    "    \n",
    "    with open(f'metrics_{safe_name}.json', 'w') as f:\n",
    "        json.dump(metrics_sgd, f, indent=2)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'models/scaler.joblib')\n",
    "\n",
    "print(\"\\n\u2705 Gradient descent models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross_validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. CROSS-VALIDATION ANALYSIS\n",
    "print(\"=\"*60)\n",
    "print(\"6. CROSS-VALIDATION ANALYSIS (5-Fold)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models_to_cv = {\n",
    "    'Linear (Uni)': (lr_uni, X_train_uni),\n",
    "    'Linear (Multi)': (lr_multi, X_train),\n",
    "    'Linear (FS)': (lr_fs, X_train_fs),\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for name, (model, X_data) in models_to_cv.items():\n",
    "    # R\u00b2 cross-validation\n",
    "    cv_r2 = cross_val_score(model, X_data, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    # Negative MSE cross-validation\n",
    "    cv_mse = cross_val_score(model, X_data, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'r2_mean': cv_r2.mean(),\n",
    "        'r2_std': cv_r2.std(),\n",
    "        'mse_mean': -cv_mse.mean(),\n",
    "        'mse_std': cv_mse.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  R\u00b2: {cv_r2.mean():.4f} \u00b1 {cv_r2.std():.4f}\")\n",
    "    print(f\"  MSE: {-cv_mse.mean():.4f} \u00b1 {cv_mse.std():.4f}\")\n",
    "\n",
    "# Save CV results\n",
    "with open('models/cv_results.json', 'w') as f:\n",
    "    json.dump(cv_results, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Cross-validation results saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. FINAL MODEL COMPARISON\n",
    "print(\"=\"*60)\n",
    "print(\"7. FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_metrics = [\n",
    "    metrics_uni,\n",
    "    metrics_multi,\n",
    "    metrics_fs,\n",
    "    results_poly[2]['metrics'],\n",
    "    results_poly[3]['metrics'],\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(all_metrics)\n",
    "comparison_df = comparison_df[['model_name', 'train_r2', 'test_r2', 'train_rmse', 'test_rmse', 'cv_r2_mean', 'cv_r2_std']]\n",
    "comparison_df = comparison_df.sort_values('test_r2', ascending=False)\n",
    "\n",
    "print(\"\\nModel Performance Ranking (by Test R\u00b2):\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv('models/model_comparison.csv', index=False)\n",
    "\n",
    "best_model = comparison_df.iloc[0]['model_name']\n",
    "best_r2 = comparison_df.iloc[0]['test_r2']\n",
    "\n",
    "print(f\"\\n\ud83c\udfc6 Best Model: {best_model}\")\n",
    "print(f\"   Test R\u00b2: {best_r2:.4f}\")\n",
    "\n",
    "print(\"\\n\u2705 Comparison saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. SUMMARY\n",
    "print(\"=\"*60)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "ALGORITHMS IMPLEMENTED:\n",
    "1. \u2705 Linear Regression (Univariate) - using rm feature\n",
    "2. \u2705 Linear Regression (Multivariate) - using all features\n",
    "3. \u2705 Linear Regression (Feature Selection) - top correlated features\n",
    "4. \u2705 Polynomial Regression (Degree 2 & 3)\n",
    "5. \u2705 Gradient Descent (SGDRegressor)\n",
    "\n",
    "KEY CONCEPTS COVERED:\n",
    "1. \u2705 Regression - predicting house prices\n",
    "2. \u2705 Overfitting vs Underfitting - analyzed in model evaluation\n",
    "3. \u2705 Cross-validation - 5-fold CV performed\n",
    "4. \u2705 Feature Selection - using correlation analysis\n",
    "\n",
    "FILES SAVED IN 'models/':\n",
    "- Models: *.joblib\n",
    "- Predictions: *.npy\n",
    "- Metrics: *.json\n",
    "- Data splits: X_train.csv, X_test.csv, y_train.csv, y_test.csv\n",
    "- Model comparison: model_comparison.csv\n",
    "\"\"\")\n",
    "\n",
    "# List all saved files\n",
    "saved_files = os.listdir('models')\n",
    "print(f\"Total files saved: {len(saved_files)}\")\n",
    "print(\"\\nFiles:\", sorted(saved_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project",
   "language": "python",
   "name": "ml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}