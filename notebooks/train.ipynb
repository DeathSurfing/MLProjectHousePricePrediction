{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create results directory\n",
    "PROJECT_DIR = '../'\n",
    "RESULTS_DIR = os.path.join(PROJECT_DIR, 'results')\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07801b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/adityavikrammahendru/.cache/kagglehub/datasets/arunjangir245/boston-housing-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"arunjangir245/boston-housing-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning: 0\n",
      "Training set: 354 samples\n",
      "Test set: 152 samples\n",
      "Data saved to results/\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset using the path from kagglehub\n",
    "df = pd.read_csv(path + '/BostonHousing.csv')\n",
    "\n",
    "# Handle missing values - fill all numeric columns with median\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "# Verify no missing values\n",
    "print(f\"Missing values after cleaning: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('medv', axis=1)\n",
    "y = df['medv']\n",
    "\n",
    "# Train/test split (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Save split data\n",
    "X_train.to_csv(RESULTS_DIR + '/X_train.csv', index=False)\n",
    "X_test.to_csv(RESULTS_DIR + '/X_test.csv', index=False)\n",
    "y_train.to_csv(RESULTS_DIR + '/y_train.csv', index=False)\n",
    "y_test.to_csv(RESULTS_DIR + '/y_test.csv', index=False)\n",
    "print(\"Data saved to results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "evaluation_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Evaluate model and return metrics\"\"\"\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'train_mse': mean_squared_error(y_train, y_train_pred),\n",
    "        'test_mse': mean_squared_error(y_test, y_test_pred),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
    "        'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
    "        'train_r2': r2_score(y_train, y_train_pred),\n",
    "        'test_r2': r2_score(y_test, y_test_pred),\n",
    "    }\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    metrics['cv_r2_mean'] = cv_scores.mean()\n",
    "    metrics['cv_r2_std'] = cv_scores.std()\n",
    "    \n",
    "    return metrics, y_test_pred\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"Print model metrics\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Model: {metrics['model_name']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Train MSE: {metrics['train_mse']:.4f} | Test MSE: {metrics['test_mse']:.4f}\")\n",
    "    print(f\"Train RMSE: {metrics['train_rmse']:.4f} | Test RMSE: {metrics['test_rmse']:.4f}\")\n",
    "    print(f\"Train MAE: {metrics['train_mae']:.4f} | Test MAE: {metrics['test_mae']:.4f}\")\n",
    "    print(f\"Train R\u00b2: {metrics['train_r2']:.4f} | Test R\u00b2: {metrics['test_r2']:.4f}\")\n",
    "    print(f\"CV R\u00b2 (mean\u00b1std): {metrics['cv_r2_mean']:.4f} \u00b1 {metrics['cv_r2_std']:.4f}\")\n",
    "\n",
    "    # Overfitting/Underfitting analysis\n",
    "    diff = metrics['train_r2'] - metrics['test_r2']\n",
    "    if diff > 0.1:\n",
    "        print(f\"\u26a0\ufe0f  Overfitting detected (train-test R\u00b2 gap: {diff:.4f})\")\n",
    "    elif metrics['train_r2'] < 0.5 and metrics['test_r2'] < 0.5:\n",
    "        print(f\"\u26a0\ufe0f  Underfitting detected (low R\u00b2 on both sets)\")\n",
    "    else:\n",
    "        print(f\"\u2705 Good fit\")\n",
    "\n",
    "print(\"Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "linear_univariate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. UNIVARIATE LINEAR REGRESSION (rm \u2192 medv)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "Model: Linear Regression (Univariate)\n",
      "==================================================\n",
      "Train MSE: 44.9427 | Test MSE: 40.3866\n",
      "Train RMSE: 6.7039 | Test RMSE: 6.3550\n",
      "Train MAE: 4.5033 | Test MAE: 4.3207\n",
      "Train R\u00b2: 0.4887 | Test R\u00b2: 0.4580\n",
      "CV R\u00b2 (mean\u00b1std): 0.4524 \u00b1 0.1773\n",
      "\u26a0\ufe0f  Underfitting detected (low R\u00b2 on both sets)\n",
      "\n",
      "\u2705 Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 1. UNIVARIATE LINEAR REGRESSION\n",
    "# Using only 'rm' (rooms) - strongest correlation with target\n",
    "print(\"=\"*60)\n",
    "print(\"1. UNIVARIATE LINEAR REGRESSION (rm \u2192 medv)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train_uni = X_train[['rm']]\n",
    "X_test_uni = X_test[['rm']]\n",
    "\n",
    "lr_uni = LinearRegression()\n",
    "lr_uni.fit(X_train_uni, y_train)\n",
    "\n",
    "metrics_uni, pred_uni = evaluate_model(lr_uni, X_train_uni, X_test_uni, y_train, y_test, \"Linear Regression (Univariate)\")\n",
    "print_metrics(metrics_uni)\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_uni, RESULTS_DIR + '/linear_univariate.joblib')\n",
    "np.save(RESULTS_DIR + '/pred_linear_univariate.npy', pred_uni)\n",
    "\n",
    "# Save metrics\n",
    "with open(RESULTS_DIR + '/metrics_linear_univariate.json', 'w') as f:\n",
    "    json.dump(metrics_uni, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "linear_multivariate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "2. MULTIVARIATE LINEAR REGRESSION (all features)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "Model: Linear Regression (Multivariate)\n",
      "==================================================\n",
      "Train MSE: 22.5704 | Test MSE: 21.6188\n",
      "Train RMSE: 4.7508 | Test RMSE: 4.6496\n",
      "Train MAE: 3.3590 | Test MAE: 3.1761\n",
      "Train R\u00b2: 0.7432 | Test R\u00b2: 0.7099\n",
      "CV R\u00b2 (mean\u00b1std): 0.6880 \u00b1 0.0923\n",
      "\u2705 Good fit\n",
      "\n",
      "Top 5 Most Important Features:\n",
      "    feature  coefficient\n",
      "4       nox   -15.423388\n",
      "5        rm     4.056626\n",
      "3      chas     3.121412\n",
      "7       dis    -1.379212\n",
      "10  ptratio    -0.912924\n",
      "\n",
      "\u2705 Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 2. MULTIVARIATE LINEAR REGRESSION\n",
    "# Using all features\n",
    "print(\"=\"*60)\n",
    "print(\"2. MULTIVARIATE LINEAR REGRESSION (all features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lr_multi = LinearRegression()\n",
    "lr_multi.fit(X_train, y_train)\n",
    "\n",
    "metrics_multi, pred_multi = evaluate_model(lr_multi, X_train, X_test, y_train, y_test, \"Linear Regression (Multivariate)\")\n",
    "print_metrics(metrics_multi)\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': lr_multi.coef_\n",
    "}).sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(feature_importance.head())\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_multi, RESULTS_DIR + '/linear_multivariate.joblib')\n",
    "np.save(RESULTS_DIR + '/pred_linear_multivariate.npy', pred_multi)\n",
    "\n",
    "# Save metrics\n",
    "with open(RESULTS_DIR + '/metrics_linear_multivariate.json', 'w') as f:\n",
    "    json.dump(metrics_multi, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "feature_selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "3. FEATURE SELECTION - Top Correlated Features\n",
      "============================================================\n",
      "Selected features: ['lstat', 'rm', 'ptratio', 'indus', 'tax', 'nox']\n",
      "\n",
      "==================================================\n",
      "Model: Linear Regression (Feature Selection)\n",
      "==================================================\n",
      "Train MSE: 27.4869 | Test MSE: 26.0001\n",
      "Train RMSE: 5.2428 | Test RMSE: 5.0990\n",
      "Train MAE: 3.6675 | Test MAE: 3.5702\n",
      "Train R\u00b2: 0.6873 | Test R\u00b2: 0.6511\n",
      "CV R\u00b2 (mean\u00b1std): 0.6512 \u00b1 0.0902\n",
      "\u2705 Good fit\n",
      "\n",
      "\u2705 Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 3. FEATURE SELECTION - Using top correlated features\n",
    "print(\"=\"*60)\n",
    "print(\"3. FEATURE SELECTION - Top Correlated Features\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Select top features based on correlation with target\n",
    "correlations = df.corr()['medv'].drop('medv').abs().sort_values(ascending=False)\n",
    "top_features = correlations.head(6).index.tolist()\n",
    "print(f\"Selected features: {top_features}\")\n",
    "\n",
    "X_train_fs = X_train[top_features]\n",
    "X_test_fs = X_test[top_features]\n",
    "\n",
    "lr_fs = LinearRegression()\n",
    "lr_fs.fit(X_train_fs, y_train)\n",
    "\n",
    "metrics_fs, pred_fs = evaluate_model(lr_fs, X_train_fs, X_test_fs, y_train, y_test, \"Linear Regression (Feature Selection)\")\n",
    "print_metrics(metrics_fs)\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_fs, RESULTS_DIR + '/linear_feature_selection.joblib')\n",
    "np.save(RESULTS_DIR + '/pred_linear_feature_selection.npy', pred_fs)\n",
    "\n",
    "with open(RESULTS_DIR + '/metrics_linear_feature_selection.json', 'w') as f:\n",
    "    json.dump(metrics_fs, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "polynomial_regression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "4. POLYNOMIAL REGRESSION\n",
      "============================================================\n",
      "\n",
      "--- Degree 2 ---\n",
      "\n",
      "==================================================\n",
      "Model: Polynomial Regression (degree=2)\n",
      "==================================================\n",
      "Train MSE: 40.7690 | Test MSE: 32.2518\n",
      "Train RMSE: 6.3851 | Test RMSE: 5.6791\n",
      "Train MAE: 4.2943 | Test MAE: 4.0268\n",
      "Train R\u00b2: 0.5362 | Test R\u00b2: 0.5672\n",
      "CV R\u00b2 (mean\u00b1std): 0.4829 \u00b1 0.2243\n",
      "\u2705 Good fit\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fRESULTS_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     25\u001b[39m results_poly[degree] = {\n\u001b[32m     26\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: lr_poly,\n\u001b[32m     27\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m: metrics_poly,\n\u001b[32m     28\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpredictions\u001b[39m\u001b[33m'\u001b[39m: pred_poly,\n\u001b[32m     29\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpoly\u001b[39m\u001b[33m'\u001b[39m: poly\n\u001b[32m     30\u001b[39m }\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m joblib.dump(lr_poly, \u001b[43mfRESULTS_DIR\u001b[49m + \u001b[33m'\u001b[39m\u001b[33m/polynomial_degree\u001b[39m\u001b[38;5;132;01m{degree}\u001b[39;00m\u001b[33m.joblib\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     34\u001b[39m joblib.dump(poly, fRESULTS_DIR + \u001b[33m'\u001b[39m\u001b[33m/polynomial_transformer_degree\u001b[39m\u001b[38;5;132;01m{degree}\u001b[39;00m\u001b[33m.joblib\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     35\u001b[39m np.save(fRESULTS_DIR + \u001b[33m'\u001b[39m\u001b[33m/pred_polynomial_degree\u001b[39m\u001b[38;5;132;01m{degree}\u001b[39;00m\u001b[33m.npy\u001b[39m\u001b[33m'\u001b[39m, pred_poly)\n",
      "\u001b[31mNameError\u001b[39m: name 'fRESULTS_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "# 4. POLYNOMIAL REGRESSION\nprint(\"=\"*60)\nprint(\"4. POLYNOMIAL REGRESSION\")\nprint(\"=\"*60)\n\nresults_poly = {}\n\nfor degree in [2, 3]:\n    print(f\"\\n--- Degree {degree} ---\")\n    \n    # Create polynomial features\n    poly = PolynomialFeatures(degree=degree, include_bias=False)\n    X_train_poly = poly.fit_transform(X_train_uni)\n    X_test_poly = poly.transform(X_test_uni)\n    \n    lr_poly = LinearRegression()\n    lr_poly.fit(X_train_poly, y_train)\n    \n    metrics_poly, pred_poly = evaluate_model(\n        lr_poly, X_train_poly, X_test_poly, y_train, y_test, \n        f\"Polynomial Regression (degree={degree})\"\n    )\n    print_metrics(metrics_poly)\n    \n    results_poly[degree] = {\n        'model': lr_poly,\n        'metrics': metrics_poly,\n        'predictions': pred_poly,\n        'poly': poly\n    }\n    \n    # Save model\n    joblib.dump(lr_poly, f'{RESULTS_DIR}/polynomial_degree{degree}.joblib')\n    joblib.dump(poly, f'{RESULTS_DIR}/polynomial_transformer_degree{degree}.joblib')\n    np.save(f'{RESULTS_DIR}/pred_polynomial_degree{degree}.npy', pred_poly)\n    \n    with open(f'{RESULTS_DIR}/metrics_polynomial_degree{degree}.json', 'w') as f:\n        json.dump(metrics_poly, f, indent=2)\n\n# Compare degrees\nprint(\"\\n\" + \"=\"*60)\nprint(\"POLYNOMIAL DEGREE COMPARISON\")\nprint(\"=\"*60)\nfor degree, data in results_poly.items():\n    m = data['metrics']\n    print(f\"Degree {degree}: Train R\u00b2={m['train_r2']:.4f}, Test R\u00b2={m['test_r2']:.4f}, CV R\u00b2={m['cv_r2_mean']:.4f}\")\n\nprint(\"\\n\u2705 Polynomial models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradient_descent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "5. GRADIENT DESCENT OPTIMIZATION (SGDRegressor)\n",
      "============================================================\n",
      "\n",
      "--- SGD (constant) ---\n",
      "\n",
      "==================================================\n",
      "Model: SGD (constant)\n",
      "==================================================\n",
      "Train MSE: 23.3203 | Test MSE: 22.7980\n",
      "Train RMSE: 4.8291 | Test RMSE: 4.7747\n",
      "Train MAE: 3.4790 | Test MAE: 3.2964\n",
      "Train R\u00b2: 0.7347 | Test R\u00b2: 0.6940\n",
      "CV R\u00b2 (mean\u00b1std): 0.6657 \u00b1 0.0882\n",
      "\u2705 Good fit\n",
      "\n",
      "--- SGD (adaptive) ---\n",
      "\n",
      "==================================================\n",
      "Model: SGD (adaptive)\n",
      "==================================================\n",
      "Train MSE: 22.6660 | Test MSE: 21.5913\n",
      "Train RMSE: 4.7609 | Test RMSE: 4.6466\n",
      "Train MAE: 3.3544 | Test MAE: 3.1626\n",
      "Train R\u00b2: 0.7421 | Test R\u00b2: 0.7102\n",
      "CV R\u00b2 (mean\u00b1std): 0.6901 \u00b1 0.0900\n",
      "\u2705 Good fit\n",
      "\n",
      "\u2705 Gradient descent models saved!\n"
     ]
    }
   ],
   "source": [
    "# 5. GRADIENT DESCENT (SGDRegressor)\nprint(\"=\"*60)\nprint(\"5. GRADIENT DESCENT OPTIMIZATION (SGDRegressor)\")\nprint(\"=\"*60)\n\n# Scale features for gradient descent\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# SGDRegressor with different configurations\nsgd_configs = [\n    {\"loss\": \"squared_error\", \"learning_rate\": \"constant\", \"eta0\": 0.01, \"name\": \"SGD (constant)\"},\n    {\"loss\": \"squared_error\", \"learning_rate\": \"adaptive\", \"eta0\": 0.01, \"name\": \"SGD (adaptive)\"},\n]\n\nresults_sgd = {}\n\nfor config in sgd_configs:\n    print(f\"\\n--- {config[\"name\"]} ---\")\n    \n    sgd = SGDRegressor(\n        loss=config[\"loss\"],\n        learning_rate=config[\"learning_rate\"],\n        eta0=config[\"eta0\"],\n        max_iter=1000,\n        random_state=42,\n        early_stopping=True,\n        validation_fraction=0.1\n    )\n    \n    sgd.fit(X_train_scaled, y_train)\n    \n    metrics_sgd, pred_sgd = evaluate_model(\n        sgd, X_train_scaled, X_test_scaled, y_train, y_test,\n        config[\"name\"]\n    )\n    print_metrics(metrics_sgd)\n    \n    results_sgd[config[\"name\"]] = {\n        \"model\": sgd,\n        \"metrics\": metrics_sgd,\n        \"predictions\": pred_sgd\n    }\n    \n    # Save model and scaler\n    safe_name = config[\"name\"].replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n    joblib.dump(sgd, f\"{RESULTS_DIR}/{safe_name}.joblib\")\n    np.save(f\"{RESULTS_DIR}/pred_{safe_name}.npy\", pred_sgd)\n    \n    with open(f\"{RESULTS_DIR}/metrics_{safe_name}.json\", \"w\") as f:\n        json.dump(metrics_sgd, f, indent=2)\n\n# Save scaler\njoblib.dump(scaler, f\"{RESULTS_DIR}/scaler.joblib\")\n\nprint(\"\\n\u2705 Gradient descent models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross_validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "6. CROSS-VALIDATION ANALYSIS (5-Fold)\n",
      "============================================================\n",
      "\n",
      "Linear (Uni):\n",
      "  R\u00b2: 0.4524 \u00b1 0.1773\n",
      "  MSE: 46.0120 \u00b1 11.4529\n",
      "\n",
      "Linear (Multi):\n",
      "  R\u00b2: 0.6880 \u00b1 0.0923\n",
      "  MSE: 25.9884 \u00b1 4.7246\n",
      "\n",
      "Linear (FS):\n",
      "  R\u00b2: 0.6512 \u00b1 0.0902\n",
      "  MSE: 29.4805 \u00b1 6.5223\n",
      "\n",
      "\u2705 Cross-validation results saved!\n"
     ]
    }
   ],
   "source": [
    "# 6. CROSS-VALIDATION ANALYSIS\n",
    "print(\"=\"*60)\n",
    "print(\"6. CROSS-VALIDATION ANALYSIS (5-Fold)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models_to_cv = {\n",
    "    'Linear (Uni)': (lr_uni, X_train_uni),\n",
    "    'Linear (Multi)': (lr_multi, X_train),\n",
    "    'Linear (FS)': (lr_fs, X_train_fs),\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for name, (model, X_data) in models_to_cv.items():\n",
    "    # R\u00b2 cross-validation\n",
    "    cv_r2 = cross_val_score(model, X_data, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    # Negative MSE cross-validation\n",
    "    cv_mse = cross_val_score(model, X_data, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'r2_mean': cv_r2.mean(),\n",
    "        'r2_std': cv_r2.std(),\n",
    "        'mse_mean': -cv_mse.mean(),\n",
    "        'mse_std': cv_mse.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  R\u00b2: {cv_r2.mean():.4f} \u00b1 {cv_r2.std():.4f}\")\n",
    "    print(f\"  MSE: {-cv_mse.mean():.4f} \u00b1 {cv_mse.std():.4f}\")\n",
    "\n",
    "# Save CV results\n",
    "with open(RESULTS_DIR + '/cv_results.json', 'w') as f:\n",
    "    json.dump(cv_results, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Cross-validation results saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "7. FINAL MODEL COMPARISON\n",
      "============================================================\n",
      "\n",
      "Model Performance Ranking (by Test R\u00b2):\n",
      "                           model_name  train_r2  test_r2  train_rmse  test_rmse  cv_r2_mean  cv_r2_std\n",
      "     Linear Regression (Multivariate)  0.743216 0.709866    4.750834   4.649599    0.688038   0.092316\n",
      "Linear Regression (Feature Selection)  0.687281 0.651066    5.242799   5.099033    0.651222   0.090185\n",
      "     Polynomial Regression (degree=3)  0.549087 0.582533    6.295528   5.577342    0.490782   0.204544\n",
      "     Polynomial Regression (degree=2)  0.536170 0.567166    6.385063   5.679065    0.482943   0.224297\n",
      "       Linear Regression (Univariate)  0.488686 0.457993    6.703935   6.355044    0.452441   0.177267\n",
      "\n",
      "\ud83c\udfc6 Best Model: Linear Regression (Multivariate)\n",
      "   Test R\u00b2: 0.7099\n",
      "\n",
      "\u2705 Comparison saved!\n"
     ]
    }
   ],
   "source": [
    "# 7. FINAL MODEL COMPARISON\n",
    "print(\"=\"*60)\n",
    "print(\"7. FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_metrics = [\n",
    "    metrics_uni,\n",
    "    metrics_multi,\n",
    "    metrics_fs,\n",
    "    results_poly[2]['metrics'],\n",
    "    results_poly[3]['metrics'],\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(all_metrics)\n",
    "comparison_df = comparison_df[['model_name', 'train_r2', 'test_r2', 'train_rmse', 'test_rmse', 'cv_r2_mean', 'cv_r2_std']]\n",
    "comparison_df = comparison_df.sort_values('test_r2', ascending=False)\n",
    "\n",
    "print(\"\\nModel Performance Ranking (by Test R\u00b2):\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv(RESULTS_DIR + '/model_comparison.csv', index=False)\n",
    "\n",
    "best_model = comparison_df.iloc[0]['model_name']\n",
    "best_r2 = comparison_df.iloc[0]['test_r2']\n",
    "\n",
    "print(f\"\\n\ud83c\udfc6 Best Model: {best_model}\")\n",
    "print(f\"   Test R\u00b2: {best_r2:.4f}\")\n",
    "\n",
    "print(\"\\n\u2705 Comparison saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROJECT SUMMARY\n",
      "============================================================\n",
      "\n",
      "ALGORITHMS IMPLEMENTED:\n",
      "1. \u2705 Linear Regression (Univariate) - using rm feature\n",
      "2. \u2705 Linear Regression (Multivariate) - using all features\n",
      "3. \u2705 Linear Regression (Feature Selection) - top correlated features\n",
      "4. \u2705 Polynomial Regression (Degree 2 & 3)\n",
      "5. \u2705 Gradient Descent (SGDRegressor)\n",
      "\n",
      "KEY CONCEPTS COVERED:\n",
      "1. \u2705 Regression - predicting house prices\n",
      "2. \u2705 Overfitting vs Underfitting - analyzed in model evaluation\n",
      "3. \u2705 Cross-validation - 5-fold CV performed\n",
      "4. \u2705 Feature Selection - using correlation analysis\n",
      "\n",
      "FILES SAVED IN 'models/':\n",
      "- Models: *.joblib\n",
      "- Predictions: *.npy\n",
      "- Metrics: *.json\n",
      "- Data splits: X_train.csv, X_test.csv, y_train.csv, y_test.csv\n",
      "- Model comparison: model_comparison.csv\n",
      "\n",
      "Total files saved: 26\n",
      "\n",
      "Files: ['SGD_adaptive.joblib', 'SGD_constant.joblib', 'X_test.csv', 'X_train.csv', 'cv_results.json', 'linear_feature_selection.joblib', 'linear_multivariate.joblib', 'linear_univariate.joblib', 'metrics_linear_feature_selection.json', 'metrics_linear_multivariate.json', 'metrics_linear_univariate.json', 'model_comparison.csv', 'polynomial_degree2.joblib', 'polynomial_degree3.joblib', 'polynomial_transformer_degree2.joblib', 'polynomial_transformer_degree3.joblib', 'pred_SGD_adaptive.npy', 'pred_SGD_constant.npy', 'pred_linear_feature_selection.npy', 'pred_linear_multivariate.npy', 'pred_linear_univariate.npy', 'pred_polynomial_degree2.npy', 'pred_polynomial_degree3.npy', 'scaler.joblib', 'y_test.csv', 'y_train.csv']\n"
     ]
    }
   ],
   "source": [
    "# 8. SUMMARY\n",
    "print(\"=\"*60)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "ALGORITHMS IMPLEMENTED:\n",
    "1. \u2705 Linear Regression (Univariate) - using rm feature\n",
    "2. \u2705 Linear Regression (Multivariate) - using all features\n",
    "3. \u2705 Linear Regression (Feature Selection) - top correlated features\n",
    "4. \u2705 Polynomial Regression (Degree 2 & 3)\n",
    "5. \u2705 Gradient Descent (SGDRegressor)\n",
    "\n",
    "KEY CONCEPTS COVERED:\n",
    "1. \u2705 Regression - predicting house prices\n",
    "2. \u2705 Overfitting vs Underfitting - analyzed in model evaluation\n",
    "3. \u2705 Cross-validation - 5-fold CV performed\n",
    "4. \u2705 Feature Selection - using correlation analysis\n",
    "\n",
    "FILES SAVED IN RESULTS_DIR + '/':\n",
    "- Models: *.joblib\n",
    "- Predictions: *.npy\n",
    "- Metrics: *.json\n",
    "- Data splits: X_train.csv, X_test.csv, y_train.csv, y_test.csv\n",
    "- Model comparison: model_comparison.csv\n",
    "\"\"\")\n",
    "\n",
    "# List all saved files\n",
    "saved_files = os.listdir('models')\n",
    "print(f\"Total files saved: {len(saved_files)}\")\n",
    "print(\"\\nFiles:\", sorted(saved_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project",
   "language": "python",
   "name": "ml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}