{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create results directory\n",
    "PROJECT_DIR = '/Users/adityavikrammahendru/Documents/GitHub/MLProjectHousePricePrediction'\n",
    "RESULTS_DIR = os.path.join(PROJECT_DIR, 'results')\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07801b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/adityavikrammahendru/.cache/kagglehub/datasets/arunjangir245/boston-housing-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"arunjangir245/boston-housing-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/adityavikrammahendru/Documents/GitHub/MLProjectHousePricePrediction/.cache/kagglehub/datasets/arunjukir245/boston-housing-dataset/versions/2/BostonHousing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPROJECT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.cache/kagglehub/datasets/arunjukir245/boston-housing-dataset/versions/2/BostonHousing.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Handle missing values - fill all numeric columns with median\u001b[39;00m\n\u001b[32m      5\u001b[39m df = df.fillna(df.median())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:873\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    861\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    862\u001b[39m     dialect,\n\u001b[32m    863\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    870\u001b[39m )\n\u001b[32m    871\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:300\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    297\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    299\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1645\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1642\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1644\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1645\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1904\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1902\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1903\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1904\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1911\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1913\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1915\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/MLProjectHousePricePrediction/.venv/lib/python3.12/site-packages/pandas/io/common.py:926\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    922\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    923\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    935\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/adityavikrammahendru/Documents/GitHub/MLProjectHousePricePrediction/.cache/kagglehub/datasets/arunjukir245/boston-housing-dataset/versions/2/BostonHousing.csv'"
     ]
    }
   ],
   "source": [
    "# Load the dataset using the path from kagglehub\ndf = pd.read_csv(path + '/BostonHousing.csv')\n\n# Handle missing values - fill all numeric columns with median\ndf = df.fillna(df.median())\n\n# Verify no missing values\nprint(f\"Missing values after cleaning: {df.isnull().sum().sum()}\")\n\n# Define features and target\nX = df.drop('medv', axis=1)\ny = df['medv']\n\n# Train/test split (70/30)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n\nprint(f\"Training set: {X_train.shape[0]} samples\")\nprint(f\"Test set: {X_test.shape[0]} samples\")\n\n# Save split data\nX_train.to_csv(RESULTS_DIR + '/X_train.csv', index=False)\nX_test.to_csv(RESULTS_DIR + '/X_test.csv', index=False)\ny_train.to_csv(RESULTS_DIR + '/y_train.csv', index=False)\ny_test.to_csv(RESULTS_DIR + '/y_test.csv', index=False)\nprint(\"Data saved to results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Evaluate model and return metrics\"\"\"\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'train_mse': mean_squared_error(y_train, y_train_pred),\n",
    "        'test_mse': mean_squared_error(y_test, y_test_pred),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
    "        'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
    "        'train_r2': r2_score(y_train, y_train_pred),\n",
    "        'test_r2': r2_score(y_test, y_test_pred),\n",
    "    }\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    metrics['cv_r2_mean'] = cv_scores.mean()\n",
    "    metrics['cv_r2_std'] = cv_scores.std()\n",
    "    \n",
    "    return metrics, y_test_pred\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"Print model metrics\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Model: {metrics['model_name']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Train MSE: {metrics['train_mse']:.4f} | Test MSE: {metrics['test_mse']:.4f}\")\n",
    "    print(f\"Train RMSE: {metrics['train_rmse']:.4f} | Test RMSE: {metrics['test_rmse']:.4f}\")\n",
    "    print(f\"Train MAE: {metrics['train_mae']:.4f} | Test MAE: {metrics['test_mae']:.4f}\")\n",
    "    print(f\"Train R\u00b2: {metrics['train_r2']:.4f} | Test R\u00b2: {metrics['test_r2']:.4f}\")\n",
    "    print(f\"CV R\u00b2 (mean\u00b1std): {metrics['cv_r2_mean']:.4f} \u00b1 {metrics['cv_r2_std']:.4f}\")\n",
    "\n",
    "    # Overfitting/Underfitting analysis\n",
    "    diff = metrics['train_r2'] - metrics['test_r2']\n",
    "    if diff > 0.1:\n",
    "        print(f\"\u26a0\ufe0f  Overfitting detected (train-test R\u00b2 gap: {diff:.4f})\")\n",
    "    elif metrics['train_r2'] < 0.5 and metrics['test_r2'] < 0.5:\n",
    "        print(f\"\u26a0\ufe0f  Underfitting detected (low R\u00b2 on both sets)\")\n",
    "    else:\n",
    "        print(f\"\u2705 Good fit\")\n",
    "\n",
    "print(\"Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear_univariate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. UNIVARIATE LINEAR REGRESSION (rm \u2192 medv)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "Model: Linear Regression (Univariate)\n",
      "==================================================\n",
      "Train MSE: 44.9427 | Test MSE: 40.3866\n",
      "Train RMSE: 6.7039 | Test RMSE: 6.3550\n",
      "Train MAE: 4.5033 | Test MAE: 4.3207\n",
      "Train R\u00b2: 0.4887 | Test R\u00b2: 0.4580\n",
      "CV R\u00b2 (mean\u00b1std): 0.4524 \u00b1 0.1773\n",
      "\u26a0\ufe0f  Underfitting detected (low R\u00b2 on both sets)\n",
      "\n",
      "\u2705 Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 1. UNIVARIATE LINEAR REGRESSION\n",
    "# Using only 'rm' (rooms) - strongest correlation with target\n",
    "print(\"=\"*60)\n",
    "print(\"1. UNIVARIATE LINEAR REGRESSION (rm \u2192 medv)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train_uni = X_train[['rm']]\n",
    "X_test_uni = X_test[['rm']]\n",
    "\n",
    "lr_uni = LinearRegression()\n",
    "lr_uni.fit(X_train_uni, y_train)\n",
    "\n",
    "metrics_uni, pred_uni = evaluate_model(lr_uni, X_train_uni, X_test_uni, y_train, y_test, \"Linear Regression (Univariate)\")\n",
    "print_metrics(metrics_uni)\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_uni, RESULTS_DIR + '/linear_univariate.joblib')\n",
    "np.save(RESULTS_DIR + '/pred_linear_univariate.npy', pred_uni)\n",
    "\n",
    "# Save metrics\n",
    "with open(RESULTS_DIR + '/metrics_linear_univariate.json', 'w') as f:\n",
    "    json.dump(metrics_uni, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear_multivariate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "2. MULTIVARIATE LINEAR REGRESSION (all features)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "Model: Linear Regression (Multivariate)\n",
      "==================================================\n",
      "Train MSE: 22.5704 | Test MSE: 21.6188\n",
      "Train RMSE: 4.7508 | Test RMSE: 4.6496\n",
      "Train MAE: 3.3590 | Test MAE: 3.1761\n",
      "Train R\u00b2: 0.7432 | Test R\u00b2: 0.7099\n",
      "CV R\u00b2 (mean\u00b1std): 0.6880 \u00b1 0.0923\n",
      "\u2705 Good fit\n",
      "\n",
      "Top 5 Most Important Features:\n",
      "    feature  coefficient\n",
      "4       nox   -15.423388\n",
      "5        rm     4.056626\n",
      "3      chas     3.121412\n",
      "7       dis    -1.379212\n",
      "10  ptratio    -0.912924\n",
      "\n",
      "\u2705 Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 2. MULTIVARIATE LINEAR REGRESSION\n",
    "# Using all features\n",
    "print(\"=\"*60)\n",
    "print(\"2. MULTIVARIATE LINEAR REGRESSION (all features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lr_multi = LinearRegression()\n",
    "lr_multi.fit(X_train, y_train)\n",
    "\n",
    "metrics_multi, pred_multi = evaluate_model(lr_multi, X_train, X_test, y_train, y_test, \"Linear Regression (Multivariate)\")\n",
    "print_metrics(metrics_multi)\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': lr_multi.coef_\n",
    "}).sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(feature_importance.head())\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_multi, RESULTS_DIR + '/linear_multivariate.joblib')\n",
    "np.save(RESULTS_DIR + '/pred_linear_multivariate.npy', pred_multi)\n",
    "\n",
    "# Save metrics\n",
    "with open(RESULTS_DIR + '/metrics_linear_multivariate.json', 'w') as f:\n",
    "    json.dump(metrics_multi, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "3. FEATURE SELECTION - Top Correlated Features\n",
      "============================================================\n",
      "Selected features: ['lstat', 'rm', 'ptratio', 'indus', 'tax', 'nox']\n",
      "\n",
      "==================================================\n",
      "Model: Linear Regression (Feature Selection)\n",
      "==================================================\n",
      "Train MSE: 27.4869 | Test MSE: 26.0001\n",
      "Train RMSE: 5.2428 | Test RMSE: 5.0990\n",
      "Train MAE: 3.6675 | Test MAE: 3.5702\n",
      "Train R\u00b2: 0.6873 | Test R\u00b2: 0.6511\n",
      "CV R\u00b2 (mean\u00b1std): 0.6512 \u00b1 0.0902\n",
      "\u2705 Good fit\n",
      "\n",
      "\u2705 Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 3. FEATURE SELECTION - Using top correlated features\n",
    "print(\"=\"*60)\n",
    "print(\"3. FEATURE SELECTION - Top Correlated Features\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Select top features based on correlation with target\n",
    "correlations = df.corr()['medv'].drop('medv').abs().sort_values(ascending=False)\n",
    "top_features = correlations.head(6).index.tolist()\n",
    "print(f\"Selected features: {top_features}\")\n",
    "\n",
    "X_train_fs = X_train[top_features]\n",
    "X_test_fs = X_test[top_features]\n",
    "\n",
    "lr_fs = LinearRegression()\n",
    "lr_fs.fit(X_train_fs, y_train)\n",
    "\n",
    "metrics_fs, pred_fs = evaluate_model(lr_fs, X_train_fs, X_test_fs, y_train, y_test, \"Linear Regression (Feature Selection)\")\n",
    "print_metrics(metrics_fs)\n",
    "\n",
    "# Save model and predictions\n",
    "joblib.dump(lr_fs, RESULTS_DIR + '/linear_feature_selection.joblib')\n",
    "np.save(RESULTS_DIR + '/pred_linear_feature_selection.npy', pred_fs)\n",
    "\n",
    "with open(RESULTS_DIR + '/metrics_linear_feature_selection.json', 'w') as f:\n",
    "    json.dump(metrics_fs, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Model and predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polynomial_regression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "4. POLYNOMIAL REGRESSION\n",
      "============================================================\n",
      "\n",
      "--- Degree 2 ---\n",
      "\n",
      "==================================================\n",
      "Model: Polynomial Regression (degree=2)\n",
      "==================================================\n",
      "Train MSE: 40.7690 | Test MSE: 32.2518\n",
      "Train RMSE: 6.3851 | Test RMSE: 5.6791\n",
      "Train MAE: 4.2943 | Test MAE: 4.0268\n",
      "Train R\u00b2: 0.5362 | Test R\u00b2: 0.5672\n",
      "CV R\u00b2 (mean\u00b1std): 0.4829 \u00b1 0.2243\n",
      "\u2705 Good fit\n",
      "\n",
      "--- Degree 3 ---\n",
      "\n",
      "==================================================\n",
      "Model: Polynomial Regression (degree=3)\n",
      "==================================================\n",
      "Train MSE: 39.6337 | Test MSE: 31.1067\n",
      "Train RMSE: 6.2955 | Test RMSE: 5.5773\n",
      "Train MAE: 4.2922 | Test MAE: 3.9042\n",
      "Train R\u00b2: 0.5491 | Test R\u00b2: 0.5825\n",
      "CV R\u00b2 (mean\u00b1std): 0.4908 \u00b1 0.2045\n",
      "\u2705 Good fit\n",
      "\n",
      "============================================================\n",
      "POLYNOMIAL DEGREE COMPARISON\n",
      "============================================================\n",
      "Degree 2: Train R\u00b2=0.5362, Test R\u00b2=0.5672, CV R\u00b2=0.4829\n",
      "Degree 3: Train R\u00b2=0.5491, Test R\u00b2=0.5825, CV R\u00b2=0.4908\n",
      "\n",
      "\u2705 Polynomial models saved!\n"
     ]
    }
   ],
   "source": [
    "# 4. POLYNOMIAL REGRESSION\n",
    "print(\"=\"*60)\n",
    "print(\"4. POLYNOMIAL REGRESSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_poly = {}\n",
    "\n",
    "for degree in [2, 3]:\n",
    "    print(f\"\\n--- Degree {degree} ---\")\n",
    "    \n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train_uni)\n",
    "    X_test_poly = poly.transform(X_test_uni)\n",
    "    \n",
    "    lr_poly = LinearRegression()\n",
    "    lr_poly.fit(X_train_poly, y_train)\n",
    "    \n",
    "    metrics_poly, pred_poly = evaluate_model(\n",
    "        lr_poly, X_train_poly, X_test_poly, y_train, y_test, \n",
    "        f\"Polynomial Regression (degree={degree})\"\n",
    "    )\n",
    "    print_metrics(metrics_poly)\n",
    "    \n",
    "    results_poly[degree] = {\n",
    "        'model': lr_poly,\n",
    "        'metrics': metrics_poly,\n",
    "        'predictions': pred_poly,\n",
    "        'poly': poly\n",
    "    }\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(lr_poly, fRESULTS_DIR + '/polynomial_degree{degree}.joblib')\n",
    "    joblib.dump(poly, fRESULTS_DIR + '/polynomial_transformer_degree{degree}.joblib')\n",
    "    np.save(fRESULTS_DIR + '/pred_polynomial_degree{degree}.npy', pred_poly)\n",
    "    \n",
    "    with open(f'metrics_polynomial_degree{degree}.json', 'w') as f:\n",
    "        json.dump(metrics_poly, f, indent=2)\n",
    "\n",
    "# Compare degrees\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POLYNOMIAL DEGREE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "for degree, data in results_poly.items():\n",
    "    m = data['metrics']\n",
    "    print(f\"Degree {degree}: Train R\u00b2={m['train_r2']:.4f}, Test R\u00b2={m['test_r2']:.4f}, CV R\u00b2={m['cv_r2_mean']:.4f}\")\n",
    "\n",
    "print(\"\\n\u2705 Polynomial models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradient_descent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "5. GRADIENT DESCENT OPTIMIZATION (SGDRegressor)\n",
      "============================================================\n",
      "\n",
      "--- SGD (constant) ---\n",
      "\n",
      "==================================================\n",
      "Model: SGD (constant)\n",
      "==================================================\n",
      "Train MSE: 23.3203 | Test MSE: 22.7980\n",
      "Train RMSE: 4.8291 | Test RMSE: 4.7747\n",
      "Train MAE: 3.4790 | Test MAE: 3.2964\n",
      "Train R\u00b2: 0.7347 | Test R\u00b2: 0.6940\n",
      "CV R\u00b2 (mean\u00b1std): 0.6657 \u00b1 0.0882\n",
      "\u2705 Good fit\n",
      "\n",
      "--- SGD (adaptive) ---\n",
      "\n",
      "==================================================\n",
      "Model: SGD (adaptive)\n",
      "==================================================\n",
      "Train MSE: 22.6660 | Test MSE: 21.5913\n",
      "Train RMSE: 4.7609 | Test RMSE: 4.6466\n",
      "Train MAE: 3.3544 | Test MAE: 3.1626\n",
      "Train R\u00b2: 0.7421 | Test R\u00b2: 0.7102\n",
      "CV R\u00b2 (mean\u00b1std): 0.6901 \u00b1 0.0900\n",
      "\u2705 Good fit\n",
      "\n",
      "\u2705 Gradient descent models saved!\n"
     ]
    }
   ],
   "source": [
    "# 5. GRADIENT DESCENT (SGDRegressor)\n",
    "print(\"=\"*60)\n",
    "print(\"5. GRADIENT DESCENT OPTIMIZATION (SGDRegressor)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Scale features for gradient descent\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SGDRegressor with different configurations\n",
    "sgd_configs = [\n",
    "    {'loss': 'squared_error', 'learning_rate': 'constant', 'eta0': 0.01, 'name': 'SGD (constant)'},\n",
    "    {'loss': 'squared_error', 'learning_rate': 'adaptive', 'eta0': 0.01, 'name': 'SGD (adaptive)'},\n",
    "]\n",
    "\n",
    "results_sgd = {}\n",
    "\n",
    "for config in sgd_configs:\n",
    "    print(f\"\\n--- {config['name']} ---\")\n",
    "    \n",
    "    sgd = SGDRegressor(\n",
    "        loss=config['loss'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        eta0=config['eta0'],\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "    \n",
    "    sgd.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    metrics_sgd, pred_sgd = evaluate_model(\n",
    "        sgd, X_train_scaled, X_test_scaled, y_train, y_test,\n",
    "        config['name']\n",
    "    )\n",
    "    print_metrics(metrics_sgd)\n",
    "    \n",
    "    results_sgd[config['name']] = {\n",
    "        'model': sgd,\n",
    "        'metrics': metrics_sgd,\n",
    "        'predictions': pred_sgd\n",
    "    }\n",
    "    \n",
    "    # Save model and scaler\n",
    "    safe_name = config['name'].replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    joblib.dump(sgd, fRESULTS_DIR + '/{safe_name}.joblib')\n",
    "    np.save(fRESULTS_DIR + '/pred_{safe_name}.npy', pred_sgd)\n",
    "    \n",
    "    with open(f'metrics_{safe_name}.json', 'w') as f:\n",
    "        json.dump(metrics_sgd, f, indent=2)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, RESULTS_DIR + '/scaler.joblib')\n",
    "\n",
    "print(\"\\n\u2705 Gradient descent models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross_validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "6. CROSS-VALIDATION ANALYSIS (5-Fold)\n",
      "============================================================\n",
      "\n",
      "Linear (Uni):\n",
      "  R\u00b2: 0.4524 \u00b1 0.1773\n",
      "  MSE: 46.0120 \u00b1 11.4529\n",
      "\n",
      "Linear (Multi):\n",
      "  R\u00b2: 0.6880 \u00b1 0.0923\n",
      "  MSE: 25.9884 \u00b1 4.7246\n",
      "\n",
      "Linear (FS):\n",
      "  R\u00b2: 0.6512 \u00b1 0.0902\n",
      "  MSE: 29.4805 \u00b1 6.5223\n",
      "\n",
      "\u2705 Cross-validation results saved!\n"
     ]
    }
   ],
   "source": [
    "# 6. CROSS-VALIDATION ANALYSIS\n",
    "print(\"=\"*60)\n",
    "print(\"6. CROSS-VALIDATION ANALYSIS (5-Fold)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models_to_cv = {\n",
    "    'Linear (Uni)': (lr_uni, X_train_uni),\n",
    "    'Linear (Multi)': (lr_multi, X_train),\n",
    "    'Linear (FS)': (lr_fs, X_train_fs),\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for name, (model, X_data) in models_to_cv.items():\n",
    "    # R\u00b2 cross-validation\n",
    "    cv_r2 = cross_val_score(model, X_data, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    # Negative MSE cross-validation\n",
    "    cv_mse = cross_val_score(model, X_data, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'r2_mean': cv_r2.mean(),\n",
    "        'r2_std': cv_r2.std(),\n",
    "        'mse_mean': -cv_mse.mean(),\n",
    "        'mse_std': cv_mse.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  R\u00b2: {cv_r2.mean():.4f} \u00b1 {cv_r2.std():.4f}\")\n",
    "    print(f\"  MSE: {-cv_mse.mean():.4f} \u00b1 {cv_mse.std():.4f}\")\n",
    "\n",
    "# Save CV results\n",
    "with open(RESULTS_DIR + '/cv_results.json', 'w') as f:\n",
    "    json.dump(cv_results, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Cross-validation results saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "7. FINAL MODEL COMPARISON\n",
      "============================================================\n",
      "\n",
      "Model Performance Ranking (by Test R\u00b2):\n",
      "                           model_name  train_r2  test_r2  train_rmse  test_rmse  cv_r2_mean  cv_r2_std\n",
      "     Linear Regression (Multivariate)  0.743216 0.709866    4.750834   4.649599    0.688038   0.092316\n",
      "Linear Regression (Feature Selection)  0.687281 0.651066    5.242799   5.099033    0.651222   0.090185\n",
      "     Polynomial Regression (degree=3)  0.549087 0.582533    6.295528   5.577342    0.490782   0.204544\n",
      "     Polynomial Regression (degree=2)  0.536170 0.567166    6.385063   5.679065    0.482943   0.224297\n",
      "       Linear Regression (Univariate)  0.488686 0.457993    6.703935   6.355044    0.452441   0.177267\n",
      "\n",
      "\ud83c\udfc6 Best Model: Linear Regression (Multivariate)\n",
      "   Test R\u00b2: 0.7099\n",
      "\n",
      "\u2705 Comparison saved!\n"
     ]
    }
   ],
   "source": [
    "# 7. FINAL MODEL COMPARISON\n",
    "print(\"=\"*60)\n",
    "print(\"7. FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_metrics = [\n",
    "    metrics_uni,\n",
    "    metrics_multi,\n",
    "    metrics_fs,\n",
    "    results_poly[2]['metrics'],\n",
    "    results_poly[3]['metrics'],\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(all_metrics)\n",
    "comparison_df = comparison_df[['model_name', 'train_r2', 'test_r2', 'train_rmse', 'test_rmse', 'cv_r2_mean', 'cv_r2_std']]\n",
    "comparison_df = comparison_df.sort_values('test_r2', ascending=False)\n",
    "\n",
    "print(\"\\nModel Performance Ranking (by Test R\u00b2):\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv(RESULTS_DIR + '/model_comparison.csv', index=False)\n",
    "\n",
    "best_model = comparison_df.iloc[0]['model_name']\n",
    "best_r2 = comparison_df.iloc[0]['test_r2']\n",
    "\n",
    "print(f\"\\n\ud83c\udfc6 Best Model: {best_model}\")\n",
    "print(f\"   Test R\u00b2: {best_r2:.4f}\")\n",
    "\n",
    "print(\"\\n\u2705 Comparison saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROJECT SUMMARY\n",
      "============================================================\n",
      "\n",
      "ALGORITHMS IMPLEMENTED:\n",
      "1. \u2705 Linear Regression (Univariate) - using rm feature\n",
      "2. \u2705 Linear Regression (Multivariate) - using all features\n",
      "3. \u2705 Linear Regression (Feature Selection) - top correlated features\n",
      "4. \u2705 Polynomial Regression (Degree 2 & 3)\n",
      "5. \u2705 Gradient Descent (SGDRegressor)\n",
      "\n",
      "KEY CONCEPTS COVERED:\n",
      "1. \u2705 Regression - predicting house prices\n",
      "2. \u2705 Overfitting vs Underfitting - analyzed in model evaluation\n",
      "3. \u2705 Cross-validation - 5-fold CV performed\n",
      "4. \u2705 Feature Selection - using correlation analysis\n",
      "\n",
      "FILES SAVED IN 'models/':\n",
      "- Models: *.joblib\n",
      "- Predictions: *.npy\n",
      "- Metrics: *.json\n",
      "- Data splits: X_train.csv, X_test.csv, y_train.csv, y_test.csv\n",
      "- Model comparison: model_comparison.csv\n",
      "\n",
      "Total files saved: 26\n",
      "\n",
      "Files: ['SGD_adaptive.joblib', 'SGD_constant.joblib', 'X_test.csv', 'X_train.csv', 'cv_results.json', 'linear_feature_selection.joblib', 'linear_multivariate.joblib', 'linear_univariate.joblib', 'metrics_linear_feature_selection.json', 'metrics_linear_multivariate.json', 'metrics_linear_univariate.json', 'model_comparison.csv', 'polynomial_degree2.joblib', 'polynomial_degree3.joblib', 'polynomial_transformer_degree2.joblib', 'polynomial_transformer_degree3.joblib', 'pred_SGD_adaptive.npy', 'pred_SGD_constant.npy', 'pred_linear_feature_selection.npy', 'pred_linear_multivariate.npy', 'pred_linear_univariate.npy', 'pred_polynomial_degree2.npy', 'pred_polynomial_degree3.npy', 'scaler.joblib', 'y_test.csv', 'y_train.csv']\n"
     ]
    }
   ],
   "source": [
    "# 8. SUMMARY\n",
    "print(\"=\"*60)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "ALGORITHMS IMPLEMENTED:\n",
    "1. \u2705 Linear Regression (Univariate) - using rm feature\n",
    "2. \u2705 Linear Regression (Multivariate) - using all features\n",
    "3. \u2705 Linear Regression (Feature Selection) - top correlated features\n",
    "4. \u2705 Polynomial Regression (Degree 2 & 3)\n",
    "5. \u2705 Gradient Descent (SGDRegressor)\n",
    "\n",
    "KEY CONCEPTS COVERED:\n",
    "1. \u2705 Regression - predicting house prices\n",
    "2. \u2705 Overfitting vs Underfitting - analyzed in model evaluation\n",
    "3. \u2705 Cross-validation - 5-fold CV performed\n",
    "4. \u2705 Feature Selection - using correlation analysis\n",
    "\n",
    "FILES SAVED IN RESULTS_DIR + '/':\n",
    "- Models: *.joblib\n",
    "- Predictions: *.npy\n",
    "- Metrics: *.json\n",
    "- Data splits: X_train.csv, X_test.csv, y_train.csv, y_test.csv\n",
    "- Model comparison: model_comparison.csv\n",
    "\"\"\")\n",
    "\n",
    "# List all saved files\n",
    "saved_files = os.listdir('models')\n",
    "print(f\"Total files saved: {len(saved_files)}\")\n",
    "print(\"\\nFiles:\", sorted(saved_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project",
   "language": "python",
   "name": "ml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}